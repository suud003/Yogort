"""
æ¸¸æˆç­–åˆ’Agentï¼ˆé…¸å¥¶ï¼‰
åŸºäºGemini APIçš„æ™ºèƒ½ç­–åˆ’è¾…åŠ©å·¥å…·
"""

import streamlit as st
from google import genai
from google.genai import types
from typing import Optional, Generator
import io
import re
import time
import base64
from datetime import datetime
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
import PyPDF2
import docx

# ============================================
# å¯ç”¨çš„Geminiæ¨¡å‹åˆ—è¡¨
# ============================================
AVAILABLE_MODELS = [
    "gemini-2.5-pro-preview-06-05",
    "gemini-2.5-flash-preview-05-20",
    "gemini-2.5-flash-preview-04-17",
    "gemini-2.5-pro-exp-03-25",
    "gemini-2.0-flash",
    "gemini-2.0-flash-lite",
    "gemini-2.0-flash-live-001",
    "gemini-1.5-pro",
    "gemini-1.5-flash",
    "gemini-1.5-flash-8b",
    "gemini-1.0-pro",
]

# æ”¯æŒæ–‡ä»¶ä¸Šä¼ çš„æ¨¡å‹åˆ—è¡¨ï¼ˆè¿™äº›æ¨¡å‹æ”¯æŒmultimodalè¾“å…¥ï¼‰
FILE_UPLOAD_SUPPORTED_MODELS = [
    "gemini-3-pro-preview",
    "gemini-2.5-pro-preview-06-05",
    "gemini-2.5-flash-preview-05-20",
    "gemini-2.5-flash-preview-04-17",
    "gemini-2.5-pro-exp-03-25",
    "gemini-2.0-flash",
    "gemini-2.0-flash-lite",
    "gemini-1.5-pro",
    "gemini-1.5-flash",
    "gemini-1.5-flash-8b",
]

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹
SUPPORTED_FILE_TYPES = ["pdf", "docx", "txt", "md"]

# ============================================
# ç³»ç»Ÿæç¤ºè¯é…ç½®
# ============================================

# ç”Ÿæˆç­–åˆ’æ¡ˆçš„System Prompt
GENERATE_PRD_SYSTEM_PROMPT = """ä½ æ˜¯èµ„æ·±æ¸¸æˆç­–åˆ’"é…¸å¥¶"ã€‚

ã€è¯­è¨€çº¦æŸã€‘
- ä¸¥ç¦åœ¨æ­£æ–‡ä¸­ä½¿ç”¨è‹±æ–‡ï¼ˆä»£ç å˜é‡é™¤å¤–ï¼‰
- ä¸éœ€è¦AIç”Ÿæˆçš„åŠŸèƒ½ç”¨è‹±æ–‡è§£é‡Šï¼ˆä¾‹å¦‚ä¸è¦å†™ "Feature Overview"ï¼Œå¿…é¡»å†™ "åŠŸèƒ½æ¦‚è¿°"ï¼‰
- æ‰€æœ‰æ ‡é¢˜ã€å†…å®¹å¿…é¡»ä½¿ç”¨ä¸­æ–‡

ã€æ ¼å¼çº¦æŸã€‘
- æ ‡é¢˜å±‚çº§ä¸¥æ ¼ä½¿ç”¨ç®€å•çš„æ•°å­—æ ¼å¼ï¼ˆå¦‚ 1ã€2ã€3... æˆ– 1.1ã€1.2...ï¼‰
- ä¸è¦ä½¿ç”¨ Markdown çš„ # ç¬¦å·æˆ–è‹±æ–‡å­—æ¯ä½œä¸ºæ ‡é¢˜ç´¢å¼•
- ä¿æŒæ–‡æ¡£ç»“æ„æ¸…æ™°æ•´æ´

ã€å†…å®¹ç»“æ„ã€‘
ä½ å¿…é¡»æŒ‰ç…§ä»¥ä¸‹10ä¸ªç« èŠ‚æ¥æ’°å†™ç­–åˆ’æ¡ˆï¼š

1ã€åŠŸèƒ½æ¦‚è¿°ï¼ˆä¸€å¥è¯è¯´æ¸…åšä»€ä¹ˆï¼‰
2ã€æˆ˜ç•¥å®šä½ï¼ˆè§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œä¸ºè°è§£å†³ï¼‰
3ã€ç”¨æˆ·åœºæ™¯ï¼ˆå…·ä½“ä½¿ç”¨æµç¨‹å’Œè§¦å‘ç‚¹ï¼‰
4ã€åŠŸèƒ½è§„æ ¼ï¼ˆè¯¦ç»†çš„åŠŸèƒ½ç‚¹å’Œäº¤äº’ï¼‰
5ã€AIå¤„ç†é€»è¾‘ï¼ˆæ¨¡å‹è°ƒç”¨ã€æ•°æ®å¤„ç†æµç¨‹ï¼‰
6ã€å®¹é”™è®¾è®¡ï¼ˆå‡ºé”™æ—¶çš„ä½“éªŒä¿éšœï¼‰
7ã€éªŒæ”¶æ ‡å‡†ï¼ˆå¦‚ä½•åˆ¤æ–­åŠŸèƒ½æˆåŠŸï¼‰
8ã€èƒ½åŠ›è¾¹ç•Œï¼ˆæ˜ç¡®ä»€ä¹ˆä¸èƒ½åšï¼‰
9ã€æŠ€æœ¯ä¾èµ–ï¼ˆéœ€è¦çš„æŠ€æœ¯èµ„æºå’Œæ¥å£ï¼‰
10ã€ç‰ˆæœ¬è§„åˆ’ï¼ˆåˆ†é˜¶æ®µå®æ–½è®¡åˆ’ï¼‰

è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„åŠŸèƒ½æè¿°ï¼Œç”Ÿæˆå®Œæ•´ã€ä¸“ä¸šçš„ç­–åˆ’æ¡ˆã€‚"""

# åˆå§‹ä¿®æ­£çš„System Prompt
INITIAL_FIX_SYSTEM_PROMPT = """ä½ æ˜¯èµ„æ·±æ¸¸æˆç­–åˆ’"é…¸å¥¶"ã€‚

è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æ—§ç­–åˆ’æ¡ˆå’Œä¿®æ”¹æ„è§ï¼ŒåŸºäºä»¥ä¸‹å¤æ£€æ¸…å•è¿›è¡Œæ£€æŸ¥å’Œä¿®æ”¹ï¼š

ã€å¤æ£€æ¸…å•ã€‘
1. æ˜¯å¦ç”¨ä¸€å¥è¯è¯´æ¸…åŠŸèƒ½æ ¸å¿ƒï¼Ÿ
2. æ˜¯å¦æ˜ç¡®å®šä¹‰ç›®æ ‡ç”¨æˆ·å’Œä½¿ç”¨åœºæ™¯ï¼Ÿ
3. æ˜¯å¦æè¿°æ¸…æ¥šç”¨æˆ·è§¦å‘è·¯å¾„ï¼Ÿ
4. æ˜¯å¦å®šä¹‰è¾“å…¥è¦æ±‚ï¼ˆæ ¼å¼ã€é™åˆ¶ï¼‰ï¼Ÿ
5. æ˜¯å¦è¯´æ˜AIå¤„ç†é€»è¾‘ï¼ˆæ¨¡å‹ã€æµç¨‹ï¼‰ï¼Ÿ
6. æ˜¯å¦å®šä¹‰è¾“å‡ºæ ¼å¼ï¼ˆæ˜¯å¦å¯ç¼–è¾‘ï¼‰ï¼Ÿ
7. æ˜¯å¦è®¾è®¡ç”¨æˆ·ä½“éªŒæµè½¬ï¼ˆä¿®æ”¹ã€é‡è¯•ï¼‰ï¼Ÿ
8. æ˜¯å¦è®¾å®šé‡åŒ–éªŒæ”¶æ ‡å‡†ï¼Ÿ
9. æ˜¯å¦å£°æ˜èƒ½åŠ›è¾¹ç•Œï¼Ÿ
10. æ˜¯å¦åˆ—å‡ºæŠ€æœ¯ä¾èµ–ï¼Ÿ

ã€è¯­è¨€çº¦æŸã€‘
- ä¸¥ç¦åœ¨æ­£æ–‡ä¸­ä½¿ç”¨è‹±æ–‡ï¼ˆä»£ç å˜é‡é™¤å¤–ï¼‰
- æ‰€æœ‰æ ‡é¢˜ã€å†…å®¹å¿…é¡»ä½¿ç”¨ä¸­æ–‡

ã€æ ¼å¼çº¦æŸã€‘
- æ ‡é¢˜å±‚çº§ä¸¥æ ¼ä½¿ç”¨ç®€å•çš„æ•°å­—æ ¼å¼ï¼ˆå¦‚ 1ã€2ã€3... æˆ– 1.1ã€1.2...ï¼‰
- ä¸è¦ä½¿ç”¨ Markdown çš„ # ç¬¦å·æˆ–è‹±æ–‡å­—æ¯ä½œä¸ºæ ‡é¢˜ç´¢å¼•

è¯·ä¿®æ”¹å¹¶å®Œå–„ç­–åˆ’æ¡ˆã€‚"""

# å¼€å‘äººå‘˜å®¡æŸ¥çš„System Prompt
DEVELOPER_REVIEW_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæŒ‘å‰”çš„é«˜çº§å¼€å‘äººå‘˜ã€‚

è¯·é˜…è¯»å½“å‰çš„ç­–åˆ’æ¡ˆï¼Œæå‡ºå°–é”çš„é—®é¢˜ï¼ŒæŒ‡å‡ºé€»è¾‘æ¼æ´ã€ç¼ºå°‘çš„æŠ€æœ¯ç»†èŠ‚æˆ–ä¸æ˜ç¡®çš„è¾¹ç¼˜æƒ…å†µã€‚

è¯·åªåˆ—å‡ºé—®é¢˜ï¼Œä¸è¦ä¿®æ”¹æ–‡æ¡£ã€‚

é—®é¢˜æ ¼å¼è¦æ±‚ï¼š
- ä½¿ç”¨æ•°å­—ç¼–å·åˆ—å‡ºé—®é¢˜
- æ¯ä¸ªé—®é¢˜è¦å…·ä½“ã€æ˜ç¡®
- èšç„¦äºæŠ€æœ¯å¯è¡Œæ€§ã€é€»è¾‘å®Œæ•´æ€§ã€è¾¹ç•Œæƒ…å†µå¤„ç†"""

# ç­–åˆ’ä¿®æ”¹çš„System Prompt
PLANNER_FIX_PROMPT = """ä½ æ˜¯ç­–åˆ’é…¸å¥¶ã€‚

æ ¹æ®å¼€å‘äººå‘˜æå‡ºçš„ä»¥ä¸‹é—®é¢˜ï¼Œå¯¹ç­–åˆ’æ¡ˆè¿›è¡Œä¿®æ”¹ã€è¡¥å……å’Œå®Œå–„ã€‚

ã€è¯­è¨€çº¦æŸã€‘
- ä¸¥ç¦åœ¨æ­£æ–‡ä¸­ä½¿ç”¨è‹±æ–‡ï¼ˆä»£ç å˜é‡é™¤å¤–ï¼‰
- æ‰€æœ‰æ ‡é¢˜ã€å†…å®¹å¿…é¡»ä½¿ç”¨ä¸­æ–‡

ã€æ ¼å¼çº¦æŸã€‘
- ä¿æŒåŸæœ‰çš„æ–‡æ¡£ç»“æ„
- æ ‡é¢˜å±‚çº§ä¸¥æ ¼ä½¿ç”¨ç®€å•çš„æ•°å­—æ ¼å¼ï¼ˆå¦‚ 1ã€2ã€3... æˆ– 1.1ã€1.2...ï¼‰
- ä¸è¦ä½¿ç”¨ Markdown çš„ # ç¬¦å·æˆ–è‹±æ–‡å­—æ¯ä½œä¸ºæ ‡é¢˜ç´¢å¼•

è¯·é’ˆå¯¹å¼€å‘äººå‘˜çš„é—®é¢˜ï¼Œé€ä¸€å›åº”å¹¶ä¿®æ”¹ç­–åˆ’æ¡ˆã€‚"""

# å¤æ£€æ¸…å•
CHECKLIST = """
---
**ã€å¤æ£€æ¸…å•ã€‘**

â–¡ 1. æ˜¯å¦ç”¨ä¸€å¥è¯è¯´æ¸…åŠŸèƒ½æ ¸å¿ƒï¼Ÿ
â–¡ 2. æ˜¯å¦æ˜ç¡®å®šä¹‰ç›®æ ‡ç”¨æˆ·å’Œä½¿ç”¨åœºæ™¯ï¼Ÿ
â–¡ 3. æ˜¯å¦æè¿°æ¸…æ¥šç”¨æˆ·è§¦å‘è·¯å¾„ï¼Ÿ
â–¡ 4. æ˜¯å¦å®šä¹‰è¾“å…¥è¦æ±‚ï¼ˆæ ¼å¼ã€é™åˆ¶ï¼‰ï¼Ÿ
â–¡ 5. æ˜¯å¦è¯´æ˜AIå¤„ç†é€»è¾‘ï¼ˆæ¨¡å‹ã€æµç¨‹ï¼‰ï¼Ÿ
â–¡ 6. æ˜¯å¦å®šä¹‰è¾“å‡ºæ ¼å¼ï¼ˆæ˜¯å¦å¯ç¼–è¾‘ï¼‰ï¼Ÿ
â–¡ 7. æ˜¯å¦è®¾è®¡ç”¨æˆ·ä½“éªŒæµè½¬ï¼ˆä¿®æ”¹ã€é‡è¯•ï¼‰ï¼Ÿ
â–¡ 8. æ˜¯å¦è®¾å®šé‡åŒ–éªŒæ”¶æ ‡å‡†ï¼Ÿ
â–¡ 9. æ˜¯å¦å£°æ˜èƒ½åŠ›è¾¹ç•Œï¼Ÿ
â–¡ 10. æ˜¯å¦åˆ—å‡ºæŠ€æœ¯ä¾èµ–ï¼Ÿ
"""

# æ±‡æŠ¥åŠ©æ‰‹çš„System Prompt
REPORT_ASSISTANT_SYSTEM_PROMPT = """# Role: èµ„æ·±èŒåœºæ²Ÿé€šä¸“å®¶

# Profile:
ä½ æ˜¯ä¸€ä½æ“…é•¿"å‘ä¸Šç®¡ç†"å’Œ"ç»“æ„åŒ–è¡¨è¾¾"çš„èŒåœºåŠ©ç†ã€‚ä½ èƒ½å¤Ÿå°†ç¢ç‰‡åŒ–çš„å·¥ä½œä¿¡æ¯è½¬åŒ–ä¸ºé€»è¾‘æ¸…æ™°ã€ç®€æ˜æ‰¼è¦ã€é‡ç‚¹çªå‡ºçš„æ±‡æŠ¥æ–‡æ¡ˆï¼Œä¸“é—¨ç”¨äºå‘é¢†å¯¼åŒæ­¥å·¥ä½œäº‹é¡¹ã€‚

# Goals:
æ ¹æ®ç”¨æˆ·æä¾›çš„ã€å½“å‰é—®é¢˜ã€‘ã€ã€è§£å†³æ–¹æ¡ˆã€‘å’Œã€é¢„æœŸç»“æœã€‘ï¼Œæ’°å†™ä¸€ä»½ç»™é¢†å¯¼æŸ¥çœ‹çš„å·¥ä½œåŒæ­¥æ–‡æ¡ˆã€‚

# Constraints & Guidelines:
1. **ç»“æ„æ¸…æ™°**ï¼šé‡‡ç”¨"ç»“è®ºå…ˆè¡Œ"æˆ–"èƒŒæ™¯-è¡ŒåŠ¨-ç»“æœ"çš„é€»è¾‘ç»“æ„ã€‚
2. **ç®€æ˜æ‰¼è¦**ï¼šå»é™¤å†—ä½™çš„ä¿®é¥°è¯ï¼Œç”¨è¯ç²¾å‡†ï¼Œé¿å…è¿‡äºå£è¯­åŒ–ï¼Œä½†è¦é€šä¿—æ˜“æ‡‚ã€‚
3. **é€»è¾‘é€šé¡º**ï¼šæ¸…æ™°åœ°é˜è¿°å‰å› åæœï¼Œè®©é¢†å¯¼ä¸€çœ¼å°±èƒ½çœ‹æ‡‚ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšï¼Œä»¥åŠè¿™ä¹ˆåšçš„å¥½å¤„ã€‚
4. **æ ¼å¼è§„èŒƒ**ï¼šé€‚å½“ä½¿ç”¨åˆ†æ®µã€åŠ ç²—æˆ–åˆ—è¡¨ï¼Œæå‡é˜…è¯»ä½“éªŒã€‚
5. **æ•°å­¦å…¬å¼**ï¼šå¦‚æœè¾“å…¥ä¸­åŒ…å«æ•°æ®è®¡ç®—æˆ–å…¬å¼ï¼Œè¯·ä½¿ç”¨ $ æˆ– $$ åŒ…è£¹å…¬å¼ã€‚

# Output Template (è¯·ä¸¥æ ¼å‚è€ƒæ­¤æ¨¡æ¿é£æ ¼):

**ã€ä¸»é¢˜ã€‘ï¼šå…³äº[æ ¸å¿ƒäº‹é¡¹]çš„åŒæ­¥/æ±‡æŠ¥**

**1. ç°çŠ¶ä¸é—®é¢˜ï¼ˆWhyï¼‰**
ç®€è¿°å½“å‰èƒŒæ™¯ï¼ŒæŒ‡å‡ºæ ¸å¿ƒç—›ç‚¹ã€‚[å½“å‰é—®é¢˜]

**2. è§£å†³æ–¹æ¡ˆï¼ˆHowï¼‰**
é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæ‹Ÿå®š/é‡‡å–ä»¥ä¸‹æªæ–½ï¼š
*   [è§£å†³æ–¹æ¡ˆçš„å…³é”®ç‚¹1]
*   [è§£å†³æ–¹æ¡ˆçš„å…³é”®ç‚¹2]

**3. é¢„æœŸæ•ˆæœï¼ˆWhatï¼‰**
æ–¹æ¡ˆå®æ–½åï¼Œé¢„è®¡è¾¾åˆ°ä»¥ä¸‹ç›®æ ‡ï¼š
*   [é¢„æœŸç»“æœ]
"""

# å‘¨æŠ¥åŠ©æ‰‹çš„System Prompt
WEEKLY_REPORT_SYSTEM_PROMPT = """Role: ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é¡¹ç›®ç®¡ç†ä¸“å®¶å’Œè¿è¥åˆ†æå¸ˆï¼Œæ“…é•¿å°†é›¶æ•£çš„æ—¥å¸¸å·¥ä½œè®°å½•ï¼ˆæ—¥æŠ¥ï¼‰æ±‡æ€»ã€æç‚¼å¹¶é‡æ„ä¸ºé€»è¾‘æ¸…æ™°ã€é‡ç‚¹çªå‡ºçš„ä¸“ä¸šå‘¨æŠ¥ã€‚

Task: è¯·æ ¹æ®æˆ‘æä¾›çš„ã€æœ¬å‘¨æ—¥æŠ¥/å·¥ä½œè®°å½•ã€‘ï¼Œå‚è€ƒã€ç›®æ ‡é£æ ¼èŒƒä¾‹ã€‘ï¼Œç”Ÿæˆä¸€ä»½é«˜è´¨é‡çš„å‘¨æŠ¥ã€‚

Constraints & Formatting Rules (é‡è¦):
1. çº¯æ–‡æœ¬æ ¼å¼ï¼šè¯·ä¸è¦ä½¿ç”¨ä»»ä½• LaTeX æ ¼å¼ï¼ˆå¦‚ $$ æˆ– $ï¼‰ã€‚æ‰€æœ‰çš„æ•°å­—ã€ç™¾åˆ†æ¯”ã€ç‰ˆæœ¬å·ç›´æ¥ä½¿ç”¨æ™®é€šæ–‡æœ¬æ˜¾ç¤ºï¼ˆä¾‹å¦‚ï¼š-2%ã€35%ã€V420ã€1->5ï¼‰ã€‚
2. ç»“æ„å¤åˆ»ï¼šå¿…é¡»ä¸¥æ ¼éµå®ˆèŒƒä¾‹çš„å±‚çº§ç»“æ„ã€‚
   - ä¸€çº§æ ‡é¢˜ä½¿ç”¨ ã€æ ‡é¢˜ã€‘ æ ¼å¼ï¼ˆä¾‹å¦‚ï¼šã€çƒ­é—¨ç‰¹è¾‘ï¼šæ–¹å‘ä¸æœºåˆ¶å¯¹é½ã€‘ï¼‰ã€‚
   - äºŒçº§è¦ç‚¹ä½¿ç”¨ â—‹å…³é”®è¯ï¼š æ ¼å¼ï¼ˆä¾‹å¦‚ï¼šâ—‹æ–¹å‘å¯¹é½ï¼š...ï¼‰ã€‚
3. å†…å®¹æç‚¼ï¼š
   - å»é‡ä¸åˆå¹¶ï¼šä¸è¦æŒ‰"å‘¨ä¸€ã€å‘¨äºŒ"çš„æ—¶é—´æµæ°´è´¦ç½—åˆ—ã€‚è¯·å°†åŒä¸€äº‹é¡¹åœ¨ä¸åŒæ—¥æœŸçš„è¿›å±•åˆå¹¶ä¸ºä¸€ä¸ªæ¡ç›®ï¼Œåªä¿ç•™æœ€ç»ˆç»“æœæˆ–å…³é”®èŠ‚ç‚¹ã€‚
   - åˆ†ç±»å½’çº³ï¼šå°†å†…å®¹æŒ‰ä¸šåŠ¡å±æ€§åˆ†ç±»ï¼ˆå¦‚ï¼šç­–ç•¥è°ƒæ•´ã€åŠŸèƒ½è¿­ä»£ã€è¿è¥é…ç½®ã€å®¡æ ¸æµç¨‹ã€æ•°æ®åˆ†æç­‰ï¼‰ã€‚
4. è¯­è¨€é£æ ¼ï¼š
   - ä¸“ä¸šã€ç²¾ç‚¼ã€å®¢è§‚ã€‚
   - å¤šç”¨åŠ¨è¯åè¯æ­é…ï¼ˆå¦‚"å®Œæˆå¯¹é½"ã€"æ˜ç¡®é€»è¾‘"ã€"ä¿®å¤æ¼æ´"ï¼‰ã€‚
   - è§£é‡Šå› æœå…³ç³»ï¼ˆå¦‚"ä¸ºäº†ç¼“è§£å›ºåŒ–...è°ƒæ•´äº†..."ï¼‰ã€‚

Reference Example (ç›®æ ‡é£æ ¼èŒƒä¾‹):

ã€çƒ­é—¨ç‰¹è¾‘ï¼šæ–¹å‘ä¸æœºåˆ¶å¯¹é½ã€‘
â—‹æ–¹å‘å¯¹é½ï¼š å®Œæˆå†…éƒ¨ä¸å‘è¡Œä¼šè®®å¯¹é½ï¼Œæ˜ç¡®"ç‰¹è¾‘"åˆ†ç±»æ¥æºé€»è¾‘ï¼Œè®¨è®ºé…å¥—H5é‰´èµå›¢æœºåˆ¶ï¼Œç»“åˆå¸‚åœºä¾§ç½‘çº¢æµé‡åŠä½œè€…ä¸»é¡µå¢åŠ æ›å…‰
â—‹ç‰¹è¾‘æ¥æºï¼š æ—¶æ•ˆé©±åŠ¨ï¼ˆè·Ÿçƒ­ç‚¹ï¼‰ã€ç‰ˆæœ¬é©±åŠ¨ï¼ˆè·Ÿç‰ˆæœ¬å†…å®¹/IPï¼‰ã€å…´è¶£é©±åŠ¨ï¼ˆè·Ÿç©å®¶å–œå¥½ï¼‰ï¼Œç›®æ ‡æ‰“é€ "æ¯å‘¨å¿…ç©çš„é™æ—¶æ´¾å¯¹"ï¼›ç¬¬ä¸€æœŸè®¡åˆ’é”å®š"å†å²å¥½å›¾"åœˆå®šå°ä¸»é¢˜
â—‹å±•ç¤ºæœºåˆ¶ï¼š ç¡®å®šä½¿ç”¨MABç®—æ³•ï¼Œå•æ¬¡å±•ç¤ºå°‘é‡ä½œå“ï¼Œé€šè¿‡åŠ¨æ€è½®æ’­ä¿è¯æ± å†…ä½œå“çš„æ›å…‰æœºä¼š

ã€æ¨èç®—æ³•ç­–ç•¥è°ƒæ•´ã€‘
â—‹ç¼“è§£å›ºåŒ–ï¼š åˆ†æå¤´éƒ¨å›ºåŒ–é—®é¢˜ï¼Œè°ƒæ•´æ··æ’å¢åŠ "çƒ­é—¨è¶‹åŠ¿"å¤šæ ·æ€§ï¼›åˆ†æ"çŒœä½ å–œæ¬¢"çš„é›†ä¸­æ›å…‰é—®é¢˜ï¼Œæ–°çš„åŒå¡”å¬å›è™½è½¬åŒ–ç‡å¾®é™ï¼ˆ-2%ï¼‰ï¼Œä½†å¤´éƒ¨æ•ˆæœæœ‰éå¸¸æ˜æ˜¾çš„æ”¹å–„
â—‹è´¨é‡ç­›é€‰ï¼š æ–°å¢å¹³å‡å¯¹å±€æ—¶é•¿çš„å‡†å…¥ç­›é€‰æ¡ä»¶ï¼Œæé«˜ä½œå“å¢é•¿é€Ÿåº¦çš„æƒé‡ï¼Œç›¸å¯¹æ›´ä¼˜å…ˆæ¨èå¿«é€Ÿå´›èµ·çš„æ–°å†…å®¹

ã€æ ‡ç­¾ä¸å®¡æ ¸æµç¨‹ä¼˜åŒ–ã€‘
â—‹é˜ˆå€¼è°ƒæ•´ï¼š æé«˜äººå®¡ä¸¾æŠ¥é˜ˆå€¼ï¼ˆ1â†’5ï¼‰ï¼Œå‡å°‘è¯¯æŠ¥å¹²æ‰°
â—‹æµç¨‹ä¼˜åŒ–ï¼š ä¿®å¤ä½œå“æ›´æ–°åï¼Œæ²¡æœ‰é‡æ–°è¿›å…¥å®¡æ ¸çš„é—®é¢˜ï¼›å‘ç°éƒ¨åˆ†ä½œè€…åˆ©ç”¨é«˜é¢‘æ›´æ–°ï¼ŒçŸ­æš‚ç»•è¿‡æ ‡ç­¾æµç¨‹ï¼Œå·²æŠ¥å¤‡11æœˆ26æ—¥Patchä¿®å¤è¯¥æ¼æ´
"""

# ç™½çš®ä¹¦åŠ©æ‰‹çš„System Prompt
WHITEPAPER_ASSISTANT_SYSTEM_PROMPT = """# Role: PUBGM WoWæ¨¡å¼ ç‰ˆæœ¬æ–‡æ¡£æ’°å†™åŠ©ç†

# Context:
ä½ æ­£åœ¨ååŠ©æ•´ç†PUBGM WoWæ¨¡å¼ï¼ˆUGCç©æ³•ï¼‰çš„ç‰ˆæœ¬ç™½çš®ä¹¦åŠŸèƒ½åˆ—è¡¨ã€‚ç”¨æˆ·ä¼šè¾“å…¥ç®€å•çš„åŠŸèƒ½å…³é”®è¯æˆ–çŸ­è¯­ï¼Œä½ éœ€è¦å°†å…¶æ‰©å†™æˆä¸€å¥æ ‡å‡†ã€ä¸“ä¸šä¸”ä¿¡æ¯é‡å®Œæ•´çš„ç‰ˆæœ¬åŠŸèƒ½é™ˆè¿°ã€‚

# Goal:
å°†ç®€çŸ­çš„å…³é”®è¯æ‰©å†™ä¸ºæ ‡å‡†çš„"åŠŸèƒ½ç‚¹é™ˆè¿°å¥"ã€‚

# Output Rules (Strict):
1.  **å¥å¼ç»“æ„**ï¼šè¯·ä¸¥æ ¼å¥—ç”¨ä»¥ä¸‹å¥å¼è¿›è¡Œæ‰©å†™ï¼š
    `[åºå·]. æ–°å¢[åŠŸèƒ½åç§°]åŠŸèƒ½ï¼Œæ”¯æŒ[å…·ä½“æœºåˆ¶/æ“ä½œæ–¹å¼]ï¼Œç”¨äº[åº”ç”¨åœºæ™¯/å…³è”çš„è®¾å¤‡æˆ–ç³»ç»Ÿ]ã€‚`
2.  **ä¸“ä¸šæ€§**ï¼šä½¿ç”¨PUBGM WoWæ¨¡å¼çš„å¸¸ç”¨æœ¯è¯­ï¼ˆå¦‚ï¼šå¯è§†åŒ–ç¼–ç¨‹ã€è‡ªå®šä¹‰UIã€å…¨å±€å˜é‡ã€äº’åŠ¨ç‰©ä½“ã€æ­¦è£…AIç­‰ï¼‰ã€‚
3.  **ç®€æ´æ€§**ï¼šä¸è¦ä½¿ç”¨æ„Ÿå¹å·ï¼Œä¸è¦å‘è¡¨è¯„è®ºï¼Œä¸è¦ä½¿ç”¨"å¿«æ¥è¯•è¯•"ç­‰è¥é”€è¯æ±‡ã€‚åªé™ˆè¿°äº‹å®ã€‚
4.  **æ•°å­¦å…¬å¼**ï¼šå¦‚æœæ¶‰åŠæ•°å€¼é€»è¾‘ï¼Œè¯·ä½¿ç”¨ LaTeX æ ¼å¼ï¼Œä¾‹å¦‚ $y=x+1$ã€‚

# Input Example:
ç”¨æˆ·è¾“å…¥ï¼šåŠ¨ç”»ç”Ÿæˆ
è¾“å‡ºï¼š1. æ–°å¢åŠ¨ç”»ç”ŸæˆåŠŸèƒ½ï¼Œæ”¯æŒä½œè€…ä¸Šä¼ è§†é¢‘åç”Ÿæˆå¯¹åº”éª¨éª¼åŠ¨ç”»ï¼Œç”¨äºå¯è§†åŒ–ç¼–ç¨‹æ§åˆ¶æ­¦è£…AIå’Œè™šæ‹ŸæŠ•å½±è£…ç½®ã€‚

ç”¨æˆ·è¾“å…¥ï¼šè‡ªå®šä¹‰UI
è¾“å‡ºï¼š1. æ–°å¢è‡ªå®šä¹‰UIç¼–è¾‘å™¨ï¼Œæ”¯æŒåˆ›ä½œè€…è‡ªç”±æ‹–æ‹½æŒ‰é’®ä¸å›¾ç‰‡å¸ƒå±€ï¼Œç”¨äºåˆ¶ä½œä¸ªæ€§åŒ–çš„æ¸¸æˆç•Œé¢ä¸äº¤äº’èœå•ã€‚

# Workflow:
1.  åˆ†æç”¨æˆ·è¾“å…¥çš„å…³é”®è¯ã€‚
2.  è”æƒ³è¯¥åŠŸèƒ½åœ¨PUBGM WoWä¸­çš„å®é™…è¿ä½œé€»è¾‘ï¼ˆæœºåˆ¶ï¼‰å’Œç”¨é€”ï¼ˆåœºæ™¯ï¼‰ã€‚
3.  æŒ‰ç…§è§„å®šå¥å¼è¾“å‡ºã€‚
"""

# ============================================
# ä¼šè¯å†å²ç®¡ç†
# ============================================

def init_session_history():
    """åˆå§‹åŒ–ä¼šè¯å†å²å­˜å‚¨"""
    if "session_history" not in st.session_state:
        st.session_state.session_history = []


# ============================================
# å¤šè½®å¯¹è¯ç®¡ç†
# ============================================

def init_chat_history(chat_key: str):
    """
    åˆå§‹åŒ–æŒ‡å®šåŠŸèƒ½çš„å¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®åï¼ˆå¦‚ 'generate_chat', 'report_chat' ç­‰ï¼‰
    """
    if chat_key not in st.session_state:
        st.session_state[chat_key] = []

def add_chat_message(chat_key: str, role: str, content: str):
    """
    æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        role: è§’è‰²ï¼ˆ'user' æˆ– 'assistant'ï¼‰
        content: æ¶ˆæ¯å†…å®¹
    """
    init_chat_history(chat_key)
    st.session_state[chat_key].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().strftime("%H:%M:%S")
    })

def get_chat_history(chat_key: str) -> list:
    """
    è·å–å¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
    
    Returns:
        å¯¹è¯å†å²åˆ—è¡¨
    """
    init_chat_history(chat_key)
    return st.session_state[chat_key]

def clear_chat_history(chat_key: str):
    """
    æ¸…ç©ºå¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
    """
    st.session_state[chat_key] = []

def build_chat_context(chat_key: str, system_prompt: str, max_history: int = 10) -> str:
    """
    æ„å»ºåŒ…å«å¯¹è¯å†å²çš„ä¸Šä¸‹æ–‡Prompt
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        max_history: æœ€å¤§å†å²æ¶ˆæ¯æ•°é‡
    
    Returns:
        åŒ…å«å†å²ä¸Šä¸‹æ–‡çš„å®Œæ•´Prompt
    """
    history = get_chat_history(chat_key)
    
    if not history:
        return ""
    
    # åªå–æœ€è¿‘çš„Næ¡å†å²
    recent_history = history[-max_history:] if len(history) > max_history else history
    
    # æ„å»ºå¯¹è¯å†å²æ–‡æœ¬
    history_text = "\n\nã€å¯¹è¯å†å²ã€‘\n"
    for msg in recent_history:
        role_label = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
        history_text += f"{role_label}: {msg['content']}\n\n"
    
    return history_text

def render_chat_interface(chat_key: str, system_prompt: str, container, 
                          placeholder: str = "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–ä¿®æ”¹è¦æ±‚...",
                          function_context: str = ""):
    """
    æ¸²æŸ“å¤šè½®å¯¹è¯ç•Œé¢
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        container: Streamlitå®¹å™¨
        placeholder: è¾“å…¥æ¡†å ä½æ–‡æœ¬
        function_context: å½“å‰åŠŸèƒ½çš„ä¸Šä¸‹æ–‡ï¼ˆå¦‚å·²ç”Ÿæˆçš„å†…å®¹ï¼‰
    
    Returns:
        æ˜¯å¦æœ‰æ–°çš„å¯¹è¯äº§ç”Ÿ
    """
    init_chat_history(chat_key)
    history = get_chat_history(chat_key)
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    if history:
        with container:
            st.markdown("#### ğŸ’¬ å¯¹è¯å†å²")
            for i, msg in enumerate(history):
                if msg["role"] == "user":
                    st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                    st.info(msg["content"])
                else:
                    st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                    st.markdown(msg["content"])
            st.markdown("---")
    
    # ç”¨äºæ§åˆ¶å¯¹è¯è¾“å…¥çš„çŠ¶æ€
    chat_input_key = f"{chat_key}_input"
    chat_processing_key = f"{chat_key}_processing"
    
    if chat_processing_key not in st.session_state:
        st.session_state[chat_processing_key] = False
    
    # å¯¹è¯è¾“å…¥åŒºåŸŸ
    col_input, col_btn, col_clear = container.columns([6, 1, 1])
    
    with col_input:
        user_message = st.text_input(
            "ç»§ç»­å¯¹è¯",
            placeholder=placeholder,
            key=chat_input_key,
            label_visibility="collapsed"
        )
    
    with col_btn:
        send_clicked = st.button("å‘é€", key=f"{chat_key}_send", type="primary", use_container_width=True)
    
    with col_clear:
        if st.button("æ¸…ç©º", key=f"{chat_key}_clear", use_container_width=True):
            clear_chat_history(chat_key)
            st.rerun()
    
    return send_clicked, user_message, chat_processing_key

def process_chat_message(chat_key: str, user_message: str, system_prompt: str, 
                         function_context: str, output_container):
    """
    å¤„ç†ç”¨æˆ·çš„å¯¹è¯æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        user_message: ç”¨æˆ·æ¶ˆæ¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        function_context: å½“å‰åŠŸèƒ½çš„ä¸Šä¸‹æ–‡
        output_container: è¾“å‡ºå®¹å™¨
    
    Returns:
        ç”Ÿæˆçš„å›å¤å†…å®¹
    """
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    add_chat_message(chat_key, "user", user_message)
    
    # æ„å»ºå®Œæ•´çš„Prompt
    history_context = build_chat_context(chat_key, system_prompt)
    
    full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{user_message}

è¯·åŸºäºä»¥ä¸Šä¸Šä¸‹æ–‡å’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚"""
    
    # è°ƒç”¨APIç”Ÿæˆå›å¤
    full_response = ""
    was_stopped = False
    has_error = False
    error_message = ""
    
    for chunk in call_gemini_stream(full_prompt, system_prompt):
        if st.session_state.should_stop:
            was_stopped = True
            break
        
        if chunk["type"] == "text":
            full_response += chunk["content"]
            output_container.markdown(full_response + "â–Œ")
        elif chunk["type"] == "error":
            has_error = True
            error_message = chunk["content"]
            break
        elif chunk["type"] == "retry":
            st.info(chunk["content"])
    
    # ç§»é™¤å…‰æ ‡
    if full_response:
        output_container.markdown(full_response)
    
    # å¤„ç†ç»“æœ
    if has_error:
        return None, error_message
    elif was_stopped:
        if full_response:
            add_chat_message(chat_key, "assistant", full_response)
        return full_response, "å·²ä¸­æ­¢"
    else:
        add_chat_message(chat_key, "assistant", full_response)
        return full_response, None

def add_to_history(function_type: str, input_data: dict, output_data: str, 
                   download_data: bytes = None, download_filename: str = None,
                   download_mime: str = None):
    """
    æ·»åŠ è®°å½•åˆ°ä¼šè¯å†å²
    
    Args:
        function_type: åŠŸèƒ½ç±»å‹ï¼ˆç”Ÿæˆç­–åˆ’æ¡ˆ/ä¼˜åŒ–ç­–åˆ’æ¡ˆ/æ±‡æŠ¥åŠ©æ‰‹/å‘¨æŠ¥åŠ©æ‰‹/ç™½çš®ä¹¦åŠ©æ‰‹ï¼‰
        input_data: è¾“å…¥æ•°æ®å­—å…¸
        output_data: è¾“å‡ºå†…å®¹
        download_data: å¯ä¸‹è½½çš„æ–‡ä»¶æ•°æ®ï¼ˆå¯é€‰ï¼‰
        download_filename: ä¸‹è½½æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
        download_mime: æ–‡ä»¶MIMEç±»å‹ï¼ˆå¯é€‰ï¼‰
    """
    init_session_history()
    
    history_item = {
        "id": len(st.session_state.session_history) + 1,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "function_type": function_type,
        "input_data": input_data,
        "output_data": output_data,
        "download_data": download_data,
        "download_filename": download_filename,
        "download_mime": download_mime
    }
    
    st.session_state.session_history.append(history_item)

def get_history_summary(item: dict) -> str:
    """
    è·å–å†å²è®°å½•çš„æ‘˜è¦æè¿°
    
    Args:
        item: å†å²è®°å½•é¡¹
    
    Returns:
        æ‘˜è¦å­—ç¬¦ä¸²
    """
    func_type = item.get("function_type", "æœªçŸ¥")
    input_data = item.get("input_data", {})
    
    # æ ¹æ®ä¸åŒåŠŸèƒ½ç±»å‹ç”Ÿæˆä¸åŒçš„æ‘˜è¦
    if func_type == "ç”Ÿæˆç­–åˆ’æ¡ˆ":
        desc = input_data.get("åŠŸèƒ½æè¿°", "")[:30]
        return f"ğŸ“ {desc}..." if len(input_data.get("åŠŸèƒ½æè¿°", "")) > 30 else f"ğŸ“ {desc}"
    elif func_type == "ä¼˜åŒ–ç­–åˆ’æ¡ˆ":
        return f"ğŸ”„ ç­–åˆ’æ¡ˆä¼˜åŒ–"
    elif func_type == "æ±‡æŠ¥åŠ©æ‰‹":
        problem = input_data.get("å½“å‰é—®é¢˜", "")[:20]
        return f"ğŸ“Š {problem}..." if len(input_data.get("å½“å‰é—®é¢˜", "")) > 20 else f"ğŸ“Š {problem}"
    elif func_type == "å‘¨æŠ¥åŠ©æ‰‹":
        return f"ğŸ“… å‘¨æŠ¥ç”Ÿæˆ"
    elif func_type == "ç™½çš®ä¹¦åŠ©æ‰‹":
        keyword = input_data.get("åŠŸèƒ½å…³é”®è¯", "")
        return f"ğŸ“– {keyword}"
    else:
        return f"ğŸ“„ {func_type}"

def clear_session_history():
    """æ¸…ç©ºä¼šè¯å†å²"""
    st.session_state.session_history = []

def render_history_sidebar():
    """
    åœ¨ä¾§è¾¹æ æ¸²æŸ“ä¼šè¯å†å²é¢æ¿
    """
    init_session_history()
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“œ ä¼šè¯å†å²")
    
    history = st.session_state.session_history
    
    if not history:
        st.sidebar.caption("æš‚æ— å†å²è®°å½•")
        return
    
    # æ˜¾ç¤ºå†å²è®°å½•æ•°é‡å’Œæ¸…ç©ºæŒ‰é’®
    col1, col2 = st.sidebar.columns([2, 1])
    with col1:
        st.caption(f"å…± {len(history)} æ¡è®°å½•")
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©º", key="clear_history", use_container_width=True):
            clear_session_history()
            st.rerun()
    
    # å€’åºæ˜¾ç¤ºå†å²è®°å½•ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    for item in reversed(history):
        item_id = item.get("id", 0)
        timestamp = item.get("timestamp", "")
        func_type = item.get("function_type", "")
        summary = get_history_summary(item)
        
        # ä½¿ç”¨expanderæ˜¾ç¤ºæ¯æ¡è®°å½•
        with st.sidebar.expander(f"#{item_id} {summary}", expanded=False):
            st.caption(f"ğŸ• {timestamp}")
            st.caption(f"ğŸ“Œ {func_type}")
            
            # æŸ¥çœ‹è¯¦æƒ…æŒ‰é’®
            if st.button("ğŸ“„ æŸ¥çœ‹è¯¦æƒ…", key=f"view_{item_id}", use_container_width=True):
                st.session_state.viewing_history_id = item_id
                st.session_state.show_history_detail = True
                st.rerun()
            
            # å¦‚æœæœ‰ä¸‹è½½æ•°æ®ï¼Œæ˜¾ç¤ºä¸‹è½½æŒ‰é’®
            if item.get("download_data"):
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½",
                    data=item["download_data"],
                    file_name=item.get("download_filename", "download.txt"),
                    mime=item.get("download_mime", "text/plain"),
                    key=f"download_{item_id}",
                    use_container_width=True
                )


# AIè‡ªæ£€çš„System Prompt
SELF_CHECK_SYSTEM_PROMPT = """ä½ æ˜¯èµ„æ·±æ¸¸æˆç­–åˆ’"é…¸å¥¶"ï¼Œæ­£åœ¨å¯¹ç­–åˆ’æ¡ˆè¿›è¡Œå¤æ£€æ¸…å•æ£€æŸ¥ã€‚

è¯·æ ¹æ®ä»¥ä¸‹10é¡¹å¤æ£€æ¸…å•ï¼Œé€ä¸€æ£€æŸ¥ç­–åˆ’æ¡ˆçš„å®Œæ•´æ€§å’Œè§„èŒƒæ€§ï¼š

ã€å¤æ£€æ¸…å•ã€‘
1. æ˜¯å¦ç”¨ä¸€å¥è¯è¯´æ¸…åŠŸèƒ½æ ¸å¿ƒï¼Ÿ
2. æ˜¯å¦æ˜ç¡®å®šä¹‰ç›®æ ‡ç”¨æˆ·å’Œä½¿ç”¨åœºæ™¯ï¼Ÿ
3. æ˜¯å¦æè¿°æ¸…æ¥šç”¨æˆ·è§¦å‘è·¯å¾„ï¼Ÿ
4. æ˜¯å¦å®šä¹‰è¾“å…¥è¦æ±‚ï¼ˆæ ¼å¼ã€é™åˆ¶ï¼‰ï¼Ÿ
5. æ˜¯å¦è¯´æ˜AIå¤„ç†é€»è¾‘ï¼ˆæ¨¡å‹ã€æµç¨‹ï¼‰ï¼Ÿ
6. æ˜¯å¦å®šä¹‰è¾“å‡ºæ ¼å¼ï¼ˆæ˜¯å¦å¯ç¼–è¾‘ï¼‰ï¼Ÿ
7. æ˜¯å¦è®¾è®¡ç”¨æˆ·ä½“éªŒæµè½¬ï¼ˆä¿®æ”¹ã€é‡è¯•ï¼‰ï¼Ÿ
8. æ˜¯å¦è®¾å®šé‡åŒ–éªŒæ”¶æ ‡å‡†ï¼Ÿ
9. æ˜¯å¦å£°æ˜èƒ½åŠ›è¾¹ç•Œï¼Ÿ
10. æ˜¯å¦åˆ—å‡ºæŠ€æœ¯ä¾èµ–ï¼Ÿ

ã€è¾“å‡ºè¦æ±‚ã€‘
è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ£€æŸ¥ç»“æœï¼š
- å¯¹æ¯ä¸€é¡¹ï¼Œå…ˆæ ‡æ˜æ£€æŸ¥é¡¹ç¼–å·å’Œåç§°
- ç»™å‡ºåˆ¤æ–­ï¼šâœ… é€šè¿‡ / âš ï¸ éƒ¨åˆ†æ»¡è¶³ / âŒ ç¼ºå¤±
- å¦‚æœæ˜¯"éƒ¨åˆ†æ»¡è¶³"æˆ–"ç¼ºå¤±"ï¼Œè¯·è¯´æ˜å…·ä½“ç¼ºå°‘ä»€ä¹ˆå†…å®¹æˆ–æ”¹è¿›å»ºè®®
- æœ€åç»™å‡ºæ€»ä½“è¯„ä»·å’Œä¼˜å…ˆæ”¹è¿›å»ºè®®

è¯·ç”¨ä¸­æ–‡è¾“å‡ºï¼Œæ ¼å¼æ¸…æ™°æ˜“è¯»ã€‚"""


def parse_prd_to_excel_data(prd_content: str) -> list:
    """
    è§£æç­–åˆ’æ¡ˆæ–‡æœ¬ï¼Œè½¬æ¢ä¸ºExcelæ•°æ®æ ¼å¼
    æŒ‰æ ‡é¢˜å±‚çº§åˆ†é…åˆ°ä¸åŒåˆ—ï¼š
    - ä¸€çº§æ ‡é¢˜ï¼ˆå¦‚ 1ã€xxxï¼‰åœ¨ç¬¬1åˆ—
    - äºŒçº§æ ‡é¢˜ï¼ˆå¦‚ 1.1ã€xxxï¼‰åœ¨ç¬¬2åˆ—
    - ä¸‰çº§æ ‡é¢˜ï¼ˆå¦‚ 1.1.1ã€xxxï¼‰åœ¨ç¬¬3åˆ—
    - æ™®é€šå†…å®¹åœ¨æœ€è¿‘æ ‡é¢˜çš„ä¸‹ä¸€åˆ—
    
    Returns:
        list: [(row_data, level), ...] æ¯è¡Œæ•°æ®å’Œå…¶å±‚çº§
    """
    lines = prd_content.strip().split('\n')
    excel_data = []
    current_level = 0
    
    # åŒ¹é…å„çº§æ ‡é¢˜çš„æ­£åˆ™è¡¨è¾¾å¼
    # ä¸€çº§æ ‡é¢˜: 1ã€ æˆ– 1. æˆ– 1  å¼€å¤´ï¼ˆçº¯æ•°å­—ï¼‰
    level1_pattern = re.compile(r'^(\d+)[ã€\.ï¼]\s*(.+)$')
    # äºŒçº§æ ‡é¢˜: 1.1ã€ æˆ– 1.1. æˆ– 1.1 å¼€å¤´
    level2_pattern = re.compile(r'^(\d+\.\d+)[ã€\.ï¼]?\s*(.+)$')
    # ä¸‰çº§æ ‡é¢˜: 1.1.1ã€ æˆ– 1.1.1. æˆ– 1.1.1 å¼€å¤´
    level3_pattern = re.compile(r'^(\d+\.\d+\.\d+)[ã€\.ï¼]?\s*(.+)$')
    # å››çº§æ ‡é¢˜: 1.1.1.1 å¼€å¤´
    level4_pattern = re.compile(r'^(\d+\.\d+\.\d+\.\d+)[ã€\.ï¼]?\s*(.+)$')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜è¡Œï¼Œä»é«˜çº§åˆ«å¾€ä½çº§åˆ«æ£€æŸ¥
        level4_match = level4_pattern.match(line)
        level3_match = level3_pattern.match(line)
        level2_match = level2_pattern.match(line)
        level1_match = level1_pattern.match(line)
        
        if level4_match:
            # å››çº§æ ‡é¢˜ -> ç¬¬4åˆ—
            current_level = 4
            excel_data.append((line, 4))
        elif level3_match:
            # ä¸‰çº§æ ‡é¢˜ -> ç¬¬3åˆ—
            current_level = 3
            excel_data.append((line, 3))
        elif level2_match:
            # äºŒçº§æ ‡é¢˜ -> ç¬¬2åˆ—
            current_level = 2
            excel_data.append((line, 2))
        elif level1_match:
            # ä¸€çº§æ ‡é¢˜ -> ç¬¬1åˆ—
            current_level = 1
            excel_data.append((line, 1))
        else:
            # æ™®é€šå†…å®¹ -> å½“å‰æ ‡é¢˜çš„ä¸‹ä¸€åˆ—ï¼Œè‡³å°‘åœ¨ç¬¬2åˆ—
            content_level = max(current_level + 1, 2) if current_level > 0 else 1
            excel_data.append((line, content_level))
    
    return excel_data


def create_excel_file(prd_content: str, check_result: str = "") -> bytes:
    """
    åˆ›å»ºExcelæ–‡ä»¶
    
    Args:
        prd_content: ç­–åˆ’æ¡ˆå†…å®¹
        check_result: AIå¤æ£€ç»“æœï¼ˆå¯é€‰ï¼‰
    
    Returns:
        bytes: Excelæ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®
    """
    wb = Workbook()
    ws = wb.active
    ws.title = "ç­–åˆ’æ¡ˆ"
    
    # å®šä¹‰æ ·å¼
    header_font = Font(bold=True, size=14, color="FFFFFF")
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    level1_font = Font(bold=True, size=12, color="1F4E79")
    level2_font = Font(bold=True, size=11, color="2E75B6")
    level3_font = Font(bold=False, size=10, color="5B9BD5")
    normal_font = Font(size=10)
    
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    wrap_alignment = Alignment(wrap_text=True, vertical='top')
    
    # è®¾ç½®åˆ—å®½
    ws.column_dimensions['A'].width = 35
    ws.column_dimensions['B'].width = 40
    ws.column_dimensions['C'].width = 45
    ws.column_dimensions['D'].width = 50
    ws.column_dimensions['E'].width = 50
    
    # æ·»åŠ è¡¨å¤´
    headers = ["ä¸€çº§æ ‡é¢˜", "äºŒçº§æ ‡é¢˜/å†…å®¹", "ä¸‰çº§æ ‡é¢˜/è¯¦æƒ…", "å››çº§æ ‡é¢˜/è¯´æ˜", "è¯¦ç»†å†…å®¹"]
    for col, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col, value=header)
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = Alignment(horizontal='center', vertical='center')
        cell.border = thin_border
    
    # è§£æå¹¶å¡«å……ç­–åˆ’æ¡ˆå†…å®¹
    excel_data = parse_prd_to_excel_data(prd_content)
    
    row_num = 2
    for content, level in excel_data:
        # å°†å†…å®¹æ”¾åˆ°å¯¹åº”å±‚çº§çš„åˆ—
        cell = ws.cell(row=row_num, column=level, value=content)
        cell.alignment = wrap_alignment
        cell.border = thin_border
        
        # æ ¹æ®å±‚çº§è®¾ç½®å­—ä½“æ ·å¼
        if level == 1:
            cell.font = level1_font
        elif level == 2:
            cell.font = level2_font
        elif level == 3:
            cell.font = level3_font
        else:
            cell.font = normal_font
        
        # ä¸ºè¯¥è¡Œçš„æ‰€æœ‰åˆ—æ·»åŠ è¾¹æ¡†
        for col in range(1, 6):
            if col != level:
                empty_cell = ws.cell(row=row_num, column=col, value="")
                empty_cell.border = thin_border
        
        row_num += 1
    
    # å¦‚æœæœ‰å¤æ£€ç»“æœï¼Œæ·»åŠ åˆ°æ–°çš„sheet
    if check_result:
        ws_check = wb.create_sheet(title="AIå¤æ£€ç»“æœ")
        ws_check.column_dimensions['A'].width = 100
        
        # æ·»åŠ æ ‡é¢˜
        title_cell = ws_check.cell(row=1, column=1, value="AIå¤æ£€æ¸…å•æ£€æŸ¥ç»“æœ")
        title_cell.font = header_font
        title_cell.fill = header_fill
        title_cell.alignment = Alignment(horizontal='center')
        
        # è§£æå¤æ£€ç»“æœ
        check_lines = check_result.strip().split('\n')
        for idx, line in enumerate(check_lines, 2):
            cell = ws_check.cell(row=idx, column=1, value=line)
            cell.alignment = wrap_alignment
            
            # æ ¹æ®å†…å®¹è®¾ç½®æ ·å¼
            if 'âœ…' in line:
                cell.font = Font(color="228B22")  # ç»¿è‰²
            elif 'âš ï¸' in line:
                cell.font = Font(color="FF8C00")  # æ©™è‰²
            elif 'âŒ' in line:
                cell.font = Font(color="DC143C")  # çº¢è‰²
    
    # ä¿å­˜åˆ°å†…å­˜
    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    
    return output.getvalue()


def extract_text_from_pdf(file_content: bytes) -> str:
    """ä»PDFæ–‡ä»¶æå–æ–‡æœ¬"""
    try:
        pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        return f"[PDFè§£æå¤±è´¥: {str(e)}]"


def extract_text_from_docx(file_content: bytes) -> str:
    """ä»Wordæ–‡æ¡£æå–æ–‡æœ¬"""
    try:
        doc = docx.Document(io.BytesIO(file_content))
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text.strip()
    except Exception as e:
        return f"[Wordæ–‡æ¡£è§£æå¤±è´¥: {str(e)}]"


def extract_text_from_file(uploaded_file) -> str:
    """
    ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
    
    Args:
        uploaded_file: Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
    
    Returns:
        str: æå–çš„æ–‡æœ¬å†…å®¹
    """
    if uploaded_file is None:
        return ""
    
    file_name = uploaded_file.name.lower()
    file_content = uploaded_file.read()
    
    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆï¼Œä»¥ä¾¿åç»­å¯èƒ½çš„é‡å¤è¯»å–
    uploaded_file.seek(0)
    
    if file_name.endswith('.pdf'):
        return extract_text_from_pdf(file_content)
    elif file_name.endswith('.docx'):
        return extract_text_from_docx(file_content)
    elif file_name.endswith('.txt') or file_name.endswith('.md'):
        # å°è¯•å¤šç§ç¼–ç 
        for encoding in ['utf-8', 'gbk', 'gb2312', 'latin-1']:
            try:
                return file_content.decode(encoding)
            except UnicodeDecodeError:
                continue
        return "[æ–‡æœ¬æ–‡ä»¶è§£ç å¤±è´¥]"
    else:
        return "[ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹]"


def is_file_upload_supported() -> bool:
    """æ£€æŸ¥å½“å‰é€‰æ‹©çš„æ¨¡å‹æ˜¯å¦æ”¯æŒæ–‡ä»¶ä¸Šä¼ """
    current_model = get_selected_model()
    # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­ï¼ˆéƒ¨åˆ†åŒ¹é…ï¼‰
    for supported_model in FILE_UPLOAD_SUPPORTED_MODELS:
        if supported_model in current_model or current_model in supported_model:
            return True
    return False


def get_gemini_client():
    """è·å–Geminiå®¢æˆ·ç«¯å®ä¾‹"""
    api_key = st.session_state.get("api_key", "")
    if not api_key:
        st.error("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        return None
    try:
        client = genai.Client(api_key=api_key)
        return client
    except Exception as e:
        st.error(f"APIåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None


def get_selected_model():
    """è·å–å½“å‰é€‰æ‹©çš„æ¨¡å‹"""
    return st.session_state.get("selected_model", AVAILABLE_MODELS[0])


def fetch_available_models():
    """ä»APIè·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    api_key = st.session_state.get("api_key", "")
    if not api_key:
        return []
    try:
        client = genai.Client(api_key=api_key)
        models = []
        for model in client.models.list():
            # åªè·å–æ”¯æŒgenerateContentçš„æ¨¡å‹
            if hasattr(model, 'supported_actions') and 'generateContent' in model.supported_actions:
                models.append(model.name.replace("models/", ""))
            elif not hasattr(model, 'supported_actions'):
                # å¦‚æœæ²¡æœ‰supported_actionså±æ€§ï¼Œä¹Ÿæ·»åŠ ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
                model_name = model.name.replace("models/", "")
                if 'gemini' in model_name.lower():
                    models.append(model_name)
        return sorted(models) if models else AVAILABLE_MODELS
    except Exception as e:
        st.sidebar.warning(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨: {str(e)}")
        return AVAILABLE_MODELS


def call_gemini(prompt: str, system_prompt: str = "") -> Optional[str]:
    """
    è°ƒç”¨Gemini APIï¼ˆéæµå¼ï¼Œç”¨äºå†…éƒ¨å¤„ç†ï¼‰
    
    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
    
    Returns:
        APIè¿”å›çš„æ–‡æœ¬å†…å®¹ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        client = get_gemini_client()
        if client is None:
            return None
        
        # æ„å»ºé…ç½®
        config = types.GenerateContentConfig(
            system_instruction=system_prompt if system_prompt else None
        )
        
        response = client.models.generate_content(
            model=get_selected_model(),
            contents=prompt,
            config=config
        )
        return response.text
    except Exception as e:
        st.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return None


def call_gemini_stream(prompt: str, system_prompt: str = "", thinking_container=None) -> Generator[dict, None, None]:
    """
    æµå¼è°ƒç”¨Gemini APIï¼Œæ”¯æŒä¸­æ­¢ã€é”™è¯¯å±•ç¤ºã€æ€è€ƒè¿‡ç¨‹å’Œè‡ªåŠ¨é‡è¯•
    
    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        thinking_container: ç”¨äºæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„å®¹å™¨ï¼ˆå¯é€‰ï¼‰
    
    Yields:
        dict: {"type": "text"|"thinking"|"error"|"retry", "content": str}
    """
    # æ¸…ç©ºä¹‹å‰çš„é”™è¯¯
    st.session_state.last_error = ""
    st.session_state.thinking_content = ""
    
    # é‡è¯•é…ç½®
    max_retries = 3
    retry_delay = 5  # ç§’
    retryable_errors = ["503", "429", "overloaded", "UNAVAILABLE", "RESOURCE_EXHAUSTED", "rate limit"]
    
    for attempt in range(max_retries):
        try:
            client = get_gemini_client()
            if client is None:
                yield {"type": "error", "content": "APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Key"}
                return
            
            # æ„å»ºé…ç½® - å¯ç”¨æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
            config = types.GenerateContentConfig(
                system_instruction=system_prompt if system_prompt else None,
                # å°è¯•å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆéƒ¨åˆ†æ¨¡å‹æ”¯æŒï¼‰
                thinking_config=types.ThinkingConfig(
                    thinking_budget=10000  # å…è®¸çš„æ€è€ƒtokenæ•°
                ) if "2.5" in get_selected_model() or "think" in get_selected_model().lower() else None
            )
            
            # ä½¿ç”¨æµå¼API
            response_stream = client.models.generate_content_stream(
                model=get_selected_model(),
                contents=prompt,
                config=config
            )
            
            for chunk in response_stream:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ­¢
                if st.session_state.should_stop:
                    yield {"type": "stopped", "content": "ç”¨æˆ·å·²ä¸­æ­¢ç”Ÿæˆ"}
                    st.session_state.should_stop = False
                    return
                
                # å¤„ç†æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                if hasattr(chunk, 'candidates') and chunk.candidates:
                    for candidate in chunk.candidates:
                        if hasattr(candidate, 'content') and candidate.content:
                            for part in candidate.content.parts:
                                # æ£€æŸ¥æ˜¯å¦æ˜¯æ€è€ƒå†…å®¹
                                if hasattr(part, 'thought') and part.thought:
                                    thinking_text = part.text if hasattr(part, 'text') else str(part)
                                    st.session_state.thinking_content += thinking_text
                                    yield {"type": "thinking", "content": thinking_text}
                                elif hasattr(part, 'text') and part.text:
                                    yield {"type": "text", "content": part.text}
                elif chunk.text:
                    yield {"type": "text", "content": chunk.text}
            
            # æˆåŠŸå®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
            return
                    
        except Exception as e:
            error_msg = str(e)
            st.session_state.last_error = error_msg
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
            is_retryable = any(err_key in error_msg for err_key in retryable_errors)
            
            if is_retryable and attempt < max_retries - 1:
                # é€šçŸ¥ç”¨æˆ·æ­£åœ¨é‡è¯•
                remaining = max_retries - attempt - 1
                yield {
                    "type": "retry", 
                    "content": f"âš ï¸ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ ({error_msg[:50]}...)ï¼Œ{retry_delay}ç§’åè‡ªåŠ¨é‡è¯•ï¼ˆå‰©ä½™{remaining}æ¬¡ï¼‰..."
                }
                time.sleep(retry_delay)
                # å¢åŠ ä¸‹æ¬¡é‡è¯•çš„ç­‰å¾…æ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
                retry_delay = min(retry_delay * 2, 30)
                continue
            else:
                # ä¸å¯é‡è¯•æˆ–å·²ç”¨å®Œé‡è¯•æ¬¡æ•°
                yield {"type": "error", "content": error_msg}
                return


def stream_to_container(prompt: str, system_prompt: str, container, thinking_container=None, status_container=None) -> tuple:
    """
    æµå¼è¾“å‡ºåˆ°Streamlitå®¹å™¨ï¼Œå®æ—¶æ˜¾ç¤ºæ‰“å­—æ•ˆæœï¼Œæ”¯æŒä¸­æ­¢ã€é”™è¯¯å±•ç¤ºå’Œæ€è€ƒè¿‡ç¨‹
    
    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        container: Streamlitå®¹å™¨å¯¹è±¡ï¼ˆå¦‚st.empty()æˆ–st.container()ï¼‰
        thinking_container: ç”¨äºæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„å®¹å™¨ï¼ˆå¯é€‰ï¼‰
        status_container: ç”¨äºæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯çš„å®¹å™¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        tuple: (å®Œæ•´çš„å“åº”æ–‡æœ¬, æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
    """
    full_response = ""
    thinking_text = ""
    error_msg = ""
    was_stopped = False
    
    # ä½¿ç”¨ç”Ÿæˆå™¨è¿›è¡Œæµå¼è¾“å‡º
    for chunk_data in call_gemini_stream(prompt, system_prompt, thinking_container):
        chunk_type = chunk_data.get("type", "text")
        chunk_content = chunk_data.get("content", "")
        
        if chunk_type == "text":
            full_response += chunk_content
            # å®æ—¶æ›´æ–°æ˜¾ç¤ºå†…å®¹ï¼Œæ·»åŠ å…‰æ ‡æ•ˆæœ
            container.markdown(full_response + " â–Œ")
        elif chunk_type == "thinking":
            thinking_text += chunk_content
            # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            if thinking_container:
                thinking_container.markdown(f"ğŸ’­ **æ¨¡å‹æ€è€ƒä¸­...**\n\n{thinking_text}")
        elif chunk_type == "retry":
            # æ˜¾ç¤ºé‡è¯•çŠ¶æ€
            if status_container:
                status_container.warning(chunk_content)
            else:
                st.warning(chunk_content)
        elif chunk_type == "error":
            error_msg = chunk_content
            if status_container:
                status_container.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {error_msg}")
            else:
                st.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {error_msg}")
            break
        elif chunk_type == "stopped":
            was_stopped = True
            if status_container:
                status_container.warning("â¹ï¸ ç”Ÿæˆå·²ä¸­æ­¢")
            break
        
        # å¼ºåˆ¶åˆ·æ–°æ˜¾ç¤º
        time.sleep(0.01)
    
    # ç§»é™¤å…‰æ ‡ï¼Œæ˜¾ç¤ºæœ€ç»ˆç»“æœ
    if full_response:
        container.markdown(full_response)
    
    # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
    success = bool(full_response) and not error_msg and not was_stopped
    
    return (full_response, success, error_msg)


def stream_generator(prompt: str, system_prompt: str):
    """
    åˆ›å»ºæµå¼è¾“å‡ºç”Ÿæˆå™¨ï¼Œé…åˆst.write_streamä½¿ç”¨
    
    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
    
    Yields:
        æ–‡æœ¬ç‰‡æ®µ
    """
    for chunk_data in call_gemini_stream(prompt, system_prompt):
        if chunk_data.get("type") == "text":
            yield chunk_data.get("content", "")


def generate_prd(user_input: str, use_stream: bool = False, container=None, thinking_container=None, status_container=None) -> tuple:
    """
    åŠŸèƒ½æ¨¡å—1ï¼šç”Ÿæˆç­–åˆ’æ¡ˆï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥çš„åŠŸèƒ½æè¿°
        use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        container: Streamlitå®¹å™¨å¯¹è±¡ï¼Œç”¨äºæµå¼æ˜¾ç¤º
        thinking_container: ç”¨äºæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„å®¹å™¨
        status_container: ç”¨äºæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯çš„å®¹å™¨
    
    Returns:
        tuple: (ç”Ÿæˆçš„ç­–åˆ’æ¡ˆæ–‡æœ¬, æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
    """
    prompt = f"è¯·æ ¹æ®ä»¥ä¸‹åŠŸèƒ½æè¿°ç”Ÿæˆå®Œæ•´çš„ç­–åˆ’æ¡ˆï¼š\n\n{user_input}"
    
    if use_stream and container:
        return stream_to_container(prompt, GENERATE_PRD_SYSTEM_PROMPT, container, thinking_container, status_container)
    else:
        result = call_gemini(prompt, GENERATE_PRD_SYSTEM_PROMPT)
        return (result, result is not None, st.session_state.last_error if not result else "")


def ai_self_check(prd_content: str, use_stream: bool = False, container=None, thinking_container=None, status_container=None) -> tuple:
    """
    AIè‡ªæ£€åŠŸèƒ½ï¼šå¯¹ç­–åˆ’æ¡ˆè¿›è¡Œå¤æ£€æ¸…å•æ£€æŸ¥ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
    
    Args:
        prd_content: ç­–åˆ’æ¡ˆå†…å®¹
        use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        container: Streamlitå®¹å™¨å¯¹è±¡ï¼Œç”¨äºæµå¼æ˜¾ç¤º
        thinking_container: ç”¨äºæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„å®¹å™¨
        status_container: ç”¨äºæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯çš„å®¹å™¨
    
    Returns:
        tuple: (æ£€æŸ¥ç»“æœæŠ¥å‘Š, æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
    """
    prompt = f"""è¯·å¯¹ä»¥ä¸‹ç­–åˆ’æ¡ˆè¿›è¡Œå¤æ£€æ¸…å•æ£€æŸ¥ï¼š

{prd_content}

è¯·é€ä¸€æ£€æŸ¥æ¯ä¸€é¡¹ï¼Œç»™å‡ºè¯¦ç»†çš„æ£€æŸ¥ç»“æœã€‚"""
    
    if use_stream and container:
        return stream_to_container(prompt, SELF_CHECK_SYSTEM_PROMPT, container, thinking_container, status_container)
    else:
        result = call_gemini(prompt, SELF_CHECK_SYSTEM_PROMPT)
        return (result, result is not None, st.session_state.last_error if not result else "")


def optimize_prd_initial(old_prd: str, feedback: str, use_stream: bool = False, container=None, thinking_container=None, status_container=None) -> tuple:
    """
    ä¼˜åŒ–ç­–åˆ’æ¡ˆ - åˆå§‹ä¿®æ­£ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
    
    Args:
        old_prd: æ—§ç­–åˆ’æ¡ˆ
        feedback: ç”¨æˆ·çš„ä¿®æ”¹æ„è§
        use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        container: Streamlitå®¹å™¨å¯¹è±¡ï¼Œç”¨äºæµå¼æ˜¾ç¤º
        thinking_container: ç”¨äºæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„å®¹å™¨
        status_container: ç”¨äºæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯çš„å®¹å™¨
    
    Returns:
        tuple: (åˆæ­¥ä¿®æ­£åçš„ç­–åˆ’æ¡ˆ, æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
    """
    prompt = f"""ã€æ—§ç­–åˆ’æ¡ˆã€‘
{old_prd}

ã€ç”¨æˆ·ä¿®æ”¹æ„è§ã€‘
{feedback if feedback else "æ— ç‰¹åˆ«æ„è§ï¼Œè¯·æ ¹æ®å¤æ£€æ¸…å•è¿›è¡Œæ£€æŸ¥å’Œå®Œå–„"}

è¯·æ ¹æ®å¤æ£€æ¸…å•æ£€æŸ¥æ—§æ¡ˆï¼Œç»“åˆç”¨æˆ·æ„è§è¿›è¡Œä¿®æ”¹å’Œå¡«è¡¥ã€‚"""
    
    if use_stream and container:
        return stream_to_container(prompt, INITIAL_FIX_SYSTEM_PROMPT, container, thinking_container, status_container)
    else:
        result = call_gemini(prompt, INITIAL_FIX_SYSTEM_PROMPT)
        return (result, result is not None, st.session_state.last_error if not result else "")


def developer_review(current_prd: str, use_stream: bool = False, container=None, thinking_container=None, status_container=None) -> tuple:
    """
    å¼€å‘äººå‘˜è§’è‰²å®¡æŸ¥ç­–åˆ’æ¡ˆï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
    
    Args:
        current_prd: å½“å‰ç‰ˆæœ¬çš„ç­–åˆ’æ¡ˆ
        use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        container: Streamlitå®¹å™¨å¯¹è±¡ï¼Œç”¨äºæµå¼æ˜¾ç¤º
        thinking_container: ç”¨äºæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„å®¹å™¨
        status_container: ç”¨äºæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯çš„å®¹å™¨
    
    Returns:
        tuple: (å¼€å‘äººå‘˜æå‡ºçš„é—®é¢˜åˆ—è¡¨, æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
    """
    prompt = f"""è¯·å®¡æŸ¥ä»¥ä¸‹ç­–åˆ’æ¡ˆï¼Œæå‡ºä½ çš„é—®é¢˜å’Œç–‘è™‘ï¼š

{current_prd}"""
    
    if use_stream and container:
        return stream_to_container(prompt, DEVELOPER_REVIEW_PROMPT, container, thinking_container, status_container)
    else:
        result = call_gemini(prompt, DEVELOPER_REVIEW_PROMPT)
        return (result, result is not None, st.session_state.last_error if not result else "")


def planner_fix(current_prd: str, dev_questions: str, use_stream: bool = False, container=None, thinking_container=None, status_container=None) -> tuple:
    """
    ç­–åˆ’è§’è‰²æ ¹æ®å¼€å‘äººå‘˜é—®é¢˜ä¿®æ”¹ç­–åˆ’æ¡ˆï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
    
    Args:
        current_prd: å½“å‰ç‰ˆæœ¬çš„ç­–åˆ’æ¡ˆ
        dev_questions: å¼€å‘äººå‘˜æå‡ºçš„é—®é¢˜
        use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        container: Streamlitå®¹å™¨å¯¹è±¡ï¼Œç”¨äºæµå¼æ˜¾ç¤º
        thinking_container: ç”¨äºæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„å®¹å™¨
        status_container: ç”¨äºæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯çš„å®¹å™¨
    
    Returns:
        tuple: (ä¿®æ”¹åçš„ç­–åˆ’æ¡ˆ, æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
    """
    prompt = f"""ã€å½“å‰ç­–åˆ’æ¡ˆã€‘
{current_prd}

ã€å¼€å‘äººå‘˜æå‡ºçš„é—®é¢˜ã€‘
{dev_questions}

è¯·é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ä¿®æ”¹å’Œå®Œå–„ç­–åˆ’æ¡ˆã€‚"""
    
    if use_stream and container:
        return stream_to_container(prompt, PLANNER_FIX_PROMPT, container, thinking_container, status_container)
    else:
        result = call_gemini(prompt, PLANNER_FIX_PROMPT)
        return (result, result is not None, st.session_state.last_error if not result else "")


def reflection_loop(initial_prd: str, max_iterations: int) -> tuple:
    """
    Reflectionå¾ªç¯ä¼˜åŒ–ç­–åˆ’æ¡ˆï¼ˆæµå¼è¾“å‡ºç‰ˆæœ¬ï¼Œæ”¯æŒä¸­æ­¢ï¼‰
    
    Args:
        initial_prd: åˆå§‹ä¿®æ­£åçš„ç­–åˆ’æ¡ˆ
        max_iterations: æœ€å¤§è¿­ä»£è½®æ¬¡
    
    Returns:
        tuple: (æœ€ç»ˆä¼˜åŒ–åçš„ç­–åˆ’æ¡ˆ, æ˜¯å¦è¢«ä¸­æ­¢)
    """
    current_prd = initial_prd
    was_stopped = False
    
    for i in range(max_iterations):
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ­¢
        if st.session_state.should_stop:
            was_stopped = True
            st.warning(f"â¹ï¸ è¿­ä»£å·²åœ¨ç¬¬ {i + 1} è½®å‰ä¸­æ­¢")
            break
            
        st.markdown(f"### ğŸ”„ ç¬¬ {i + 1} è½®è¿­ä»£")
        
        # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®
        col_status, col_stop = st.columns([4, 1])
        with col_stop:
            if st.button(f"â¹ï¸ ä¸­æ­¢è¿­ä»£", key=f"stop_iteration_{i}", type="secondary"):
                st.session_state.should_stop = True
                st.warning("æ­£åœ¨ä¸­æ­¢...")
        
        # è§’è‰²A: å¼€å‘äººå‘˜å®¡æŸ¥
        with st.expander(f"ğŸ“‹ ç¬¬ {i + 1} è½® - å¼€å‘äººå‘˜å®¡æŸ¥", expanded=True):
            st.markdown("**ğŸ” å¼€å‘äººå‘˜æ­£åœ¨å®¡æŸ¥ç­–åˆ’æ¡ˆ...**")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤º
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            status_container = st.empty()
            dev_container = st.empty()
            
            dev_questions, success, error = developer_review(
                current_prd, 
                use_stream=True, 
                container=dev_container,
                thinking_container=thinking_container,
                status_container=status_container
            )
            
            if st.session_state.should_stop:
                was_stopped = True
                st.warning("â¹ï¸ å·²ä¸­æ­¢")
                break
                
            if success and dev_questions:
                st.success("å®¡æŸ¥å®Œæˆï¼")
            elif error:
                st.error(f"âŒ å®¡æŸ¥å¤±è´¥: {error}")
                st.warning("è·³è¿‡æœ¬è½®")
                continue
            else:
                st.warning("å¼€å‘äººå‘˜å®¡æŸ¥å¤±è´¥ï¼Œè·³è¿‡æœ¬è½®")
                continue
        
        # è§’è‰²B: ç­–åˆ’ä¿®æ”¹
        with st.expander(f"âœï¸ ç¬¬ {i + 1} è½® - ç­–åˆ’ä¼˜åŒ–", expanded=True):
            st.markdown("**âœï¸ ç­–åˆ’é…¸å¥¶æ­£åœ¨ä¼˜åŒ–ç­–åˆ’æ¡ˆ...**")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤º
            thinking_expander2 = st.expander("ğŸ’­ æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander2:
                thinking_container2 = st.empty()
            
            status_container2 = st.empty()
            fix_container = st.empty()
            
            updated_prd, success, error = planner_fix(
                current_prd, 
                dev_questions, 
                use_stream=True, 
                container=fix_container,
                thinking_container=thinking_container2,
                status_container=status_container2
            )
            
            if st.session_state.should_stop:
                was_stopped = True
                st.warning("â¹ï¸ å·²ä¸­æ­¢")
                break
                
            if success and updated_prd:
                current_prd = updated_prd
                st.success(f"ç¬¬ {i + 1} è½®ä¼˜åŒ–å®Œæˆï¼")
            elif error:
                st.error(f"âŒ ä¼˜åŒ–å¤±è´¥: {error}")
                st.warning("ä¿æŒå½“å‰ç‰ˆæœ¬")
            else:
                st.warning("ç­–åˆ’ä¼˜åŒ–å¤±è´¥ï¼Œä¿æŒå½“å‰ç‰ˆæœ¬")
        
        st.markdown("---")
    
    return (current_prd, was_stopped)


def main():
    """ä¸»å‡½æ•°"""
    # é¡µé¢é…ç½®
    st.set_page_config(
        page_title="æ¸¸æˆç­–åˆ’Agentï¼ˆé…¸å¥¶ï¼‰",
        page_icon="ğŸ®",
        layout="wide"
    )
    
    # åˆå§‹åŒ–session_state
    if "generated_prd" not in st.session_state:
        st.session_state.generated_prd = ""
    if "optimized_prd" not in st.session_state:
        st.session_state.optimized_prd = ""
    if "is_processing" not in st.session_state:
        st.session_state.is_processing = False
    
    # åˆå§‹åŒ–ä¼šè¯å†å²
    init_session_history()
    
    # å†å²è¯¦æƒ…æŸ¥çœ‹çŠ¶æ€
    if "viewing_history_id" not in st.session_state:
        st.session_state.viewing_history_id = None
    if "show_history_detail" not in st.session_state:
        st.session_state.show_history_detail = False
    
    # å°è¯•ä» Streamlit Secrets è·å– API Keyï¼ˆç”¨äºäº‘éƒ¨ç½²ï¼‰
    default_api_key = ""
    secrets_api_key_loaded = False
    try:
        if "GOOGLE_API_KEY" in st.secrets:
            default_api_key = st.secrets["GOOGLE_API_KEY"]
            secrets_api_key_loaded = True
        elif "GEMINI_API_KEY" in st.secrets:
            default_api_key = st.secrets["GEMINI_API_KEY"]
            secrets_api_key_loaded = True
    except Exception:
        # æœ¬åœ°è¿è¡Œæ—¶å¯èƒ½æ²¡æœ‰ secrets æ–‡ä»¶
        pass
    
    if "api_key" not in st.session_state:
        st.session_state.api_key = default_api_key
    if "secrets_api_key_loaded" not in st.session_state:
        st.session_state.secrets_api_key_loaded = secrets_api_key_loaded
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = AVAILABLE_MODELS[0]
    if "models_list" not in st.session_state:
        st.session_state.models_list = AVAILABLE_MODELS
    if "api_key_validated" not in st.session_state:
        st.session_state.api_key_validated = False
    # ä¸­æ­¢æ§åˆ¶
    if "should_stop" not in st.session_state:
        st.session_state.should_stop = False
    # é”™è¯¯ä¿¡æ¯
    if "last_error" not in st.session_state:
        st.session_state.last_error = ""
    # æ€è€ƒè¿‡ç¨‹
    if "thinking_content" not in st.session_state:
        st.session_state.thinking_content = ""
    
    # ========== ä¾§è¾¹æ  - APIé…ç½® ==========
    with st.sidebar:
        st.header("âš™ï¸ API é…ç½®")
        
        # å¦‚æœä» Secrets åŠ è½½äº† API Keyï¼Œæ˜¾ç¤ºæç¤º
        if st.session_state.secrets_api_key_loaded and st.session_state.api_key:
            st.success("ğŸ” å·²ä»äº‘ç«¯é…ç½®åŠ è½½ API Key")
            # æ˜¾ç¤ºéšè—çš„ API Key çŠ¶æ€
            st.text_input(
                "ğŸ”‘ Gemini API Key",
                type="password",
                value="********ï¼ˆäº‘ç«¯é…ç½®ï¼‰",
                disabled=True,
                help="API Key å·²ä» Streamlit Secrets è‡ªåŠ¨åŠ è½½"
            )
            # æä¾›æ‰‹åŠ¨è¦†ç›–é€‰é¡¹
            with st.expander("âœï¸ ä½¿ç”¨è‡ªå®šä¹‰ API Key"):
                custom_api_key = st.text_input(
                    "è¾“å…¥è‡ªå®šä¹‰ API Key",
                    type="password",
                    placeholder="ç•™ç©ºåˆ™ä½¿ç”¨äº‘ç«¯é…ç½®çš„ Key",
                    help="å¦‚éœ€ä½¿ç”¨è‡ªå·±çš„ API Keyï¼Œè¯·åœ¨æ­¤è¾“å…¥"
                )
                if custom_api_key:
                    st.session_state.api_key = custom_api_key
                    st.session_state.secrets_api_key_loaded = False
                    st.session_state.api_key_validated = False
                    st.rerun()
            api_key_input = st.session_state.api_key
        else:
            # æ‰‹åŠ¨è¾“å…¥ API Key
            api_key_input = st.text_input(
                "ğŸ”‘ Gemini API Key",
                type="password",
                value=st.session_state.api_key,
                placeholder="è¯·è¾“å…¥æ‚¨çš„ Gemini API Key",
                help="è¯·å‰å¾€ Google AI Studio è·å– API Key: https://aistudio.google.com/apikey"
            )
            
            # æ£€æµ‹API Keyå˜åŒ–
            if api_key_input != st.session_state.api_key:
                st.session_state.api_key = api_key_input
                st.session_state.api_key_validated = False
                st.session_state.models_list = AVAILABLE_MODELS
        
        # éªŒè¯å¹¶è·å–æ¨¡å‹åˆ—è¡¨æŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ éªŒè¯ & åˆ·æ–°æ¨¡å‹", disabled=not api_key_input):
                if api_key_input:
                    with st.spinner("æ­£åœ¨éªŒè¯API Keyå¹¶è·å–æ¨¡å‹åˆ—è¡¨..."):
                        models = fetch_available_models()
                        if models:
                            st.session_state.models_list = models
                            st.session_state.api_key_validated = True
                            st.success(f"âœ… éªŒè¯æˆåŠŸï¼è·å–åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹")
                        else:
                            st.error("âŒ API Key æ— æ•ˆæˆ–æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
                            st.session_state.api_key_validated = False
        
        with col2:
            if st.session_state.api_key_validated:
                st.markdown("âœ… å·²éªŒè¯")
            elif api_key_input:
                st.markdown("âš ï¸ æœªéªŒè¯")
        
        # äº‘ç«¯éƒ¨ç½²æç¤º
        if st.session_state.secrets_api_key_loaded:
            st.caption("ğŸ’¡ äº‘ç«¯éƒ¨ç½²æ¨¡å¼ï¼šAPI Key å·²å®‰å…¨å­˜å‚¨")
        
        st.markdown("---")
        
        # æ¨¡å‹é€‰æ‹©
        st.subheader("ğŸ¤– æ¨¡å‹é€‰æ‹©")
        
        # æ¨¡å‹ä¸‹æ‹‰é€‰æ‹©æ¡†
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=st.session_state.models_list,
            index=0 if st.session_state.selected_model not in st.session_state.models_list 
                  else st.session_state.models_list.index(st.session_state.selected_model),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹"
        )
        st.session_state.selected_model = selected_model
        
        # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„æ¨¡å‹
        st.info(f"å½“å‰æ¨¡å‹: **{selected_model}**")
        
        st.markdown("---")
        
        # å¸®åŠ©ä¿¡æ¯
        with st.expander("ğŸ“– ä½¿ç”¨å¸®åŠ©"):
            st.markdown("""
            **å¦‚ä½•è·å– API Keyï¼š**
            1. è®¿é—® [Google AI Studio](https://aistudio.google.com/apikey)
            2. ç™»å½•æ‚¨çš„ Google è´¦å·
            3. ç‚¹å‡» "Create API Key" åˆ›å»ºå¯†é’¥
            4. å¤åˆ¶å¯†é’¥å¹¶ç²˜è´´åˆ°ä¸Šæ–¹è¾“å…¥æ¡†
            
            **æ¨¡å‹è¯´æ˜ï¼š**
            - `gemini-2.5-*`: æœ€æ–°ä¸€ä»£æ¨¡å‹ï¼Œèƒ½åŠ›æœ€å¼º
            - `gemini-2.0-flash`: é€Ÿåº¦å¿«ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
            - `gemini-1.5-pro`: ä¸Šä¸€ä»£Proæ¨¡å‹ï¼Œç¨³å®šå¯é 
            - `gemini-1.5-flash`: è½»é‡å¿«é€Ÿæ¨¡å‹
            
            **æ³¨æ„äº‹é¡¹ï¼š**
            - ç‚¹å‡»"éªŒè¯ & åˆ·æ–°æ¨¡å‹"å¯è·å–æœ€æ–°çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨
            - ä¸åŒæ¨¡å‹çš„èƒ½åŠ›å’Œå“åº”é€Ÿåº¦æœ‰æ‰€ä¸åŒ
            - API Key ä»…å­˜å‚¨åœ¨æœ¬åœ°æµè§ˆå™¨ä¼šè¯ä¸­
            
            **äº‘ç«¯éƒ¨ç½²ï¼ˆStreamlit Cloudï¼‰ï¼š**
            - æ”¯æŒé€šè¿‡ Secrets å®‰å…¨é…ç½® API Key
            - åœ¨ Streamlit Cloud çš„ Settings â†’ Secrets ä¸­æ·»åŠ ï¼š
            ```
            GOOGLE_API_KEY = "your-api-key"
            ```
            - æœ¬åœ°å¼€å‘æ—¶ï¼Œå¯åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.streamlit/secrets.toml`
            """)
        
        st.markdown("---")
        st.caption("Powered by Google Gemini API")
        
        # æ¸²æŸ“ä¼šè¯å†å²ä¾§è¾¹æ 
        render_history_sidebar()
    
    # ========== ä¸»ç•Œé¢ ==========
    # æ ‡é¢˜
    st.title("ğŸ® æ¸¸æˆç­–åˆ’Agentï¼ˆé…¸å¥¶ï¼‰")
    st.markdown("*åŸºäºGemini APIçš„æ™ºèƒ½ç­–åˆ’è¾…åŠ©å·¥å…·*")
    st.markdown("---")
    
    # æ£€æŸ¥API Key
    if not st.session_state.api_key:
        st.warning("âš ï¸ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ é…ç½® API Key åä½¿ç”¨æœ¬å·¥å…·")
        st.info("ğŸ‘ˆ ç‚¹å‡»å·¦ä¾§ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ Gemini API Key")
        
        # æ˜¾ç¤ºå¿«é€ŸæŒ‡å—
        with st.expander("ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—", expanded=True):
            st.markdown("""
            ### ç¬¬ä¸€æ­¥ï¼šè·å– API Key
            1. è®¿é—® [Google AI Studio](https://aistudio.google.com/apikey)
            2. ä½¿ç”¨ Google è´¦å·ç™»å½•
            3. ç‚¹å‡» "Create API Key" æŒ‰é’®
            4. å¤åˆ¶ç”Ÿæˆçš„ API Key
            
            ### ç¬¬äºŒæ­¥ï¼šé…ç½®å·¥å…·
            1. åœ¨å·¦ä¾§ä¾§è¾¹æ çš„ "API Key" è¾“å…¥æ¡†ä¸­ç²˜è´´æ‚¨çš„å¯†é’¥
            2. ç‚¹å‡» "éªŒè¯ & åˆ·æ–°æ¨¡å‹" æŒ‰é’®éªŒè¯å¯†é’¥
            3. é€‰æ‹©æ‚¨æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹
            
            ### ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹ä½¿ç”¨
            - **ç”Ÿæˆç­–åˆ’æ¡ˆ**ï¼šè¾“å…¥åŠŸèƒ½æè¿°ï¼ŒAIå°†ç”Ÿæˆå®Œæ•´çš„ç­–åˆ’æ¡ˆ
            - **ä¼˜åŒ–ç­–åˆ’æ¡ˆ**ï¼šè¾“å…¥ç°æœ‰ç­–åˆ’æ¡ˆï¼ŒAIå°†é€šè¿‡å¤šè½®è¿­ä»£ä¼˜åŒ–
            - **æ±‡æŠ¥åŠ©æ‰‹**ï¼šå°†å·¥ä½œä¿¡æ¯è½¬åŒ–ä¸ºç»“æ„åŒ–æ±‡æŠ¥æ–‡æ¡ˆ
            """)
        st.stop()
    
    # ========== å†å²è¯¦æƒ…æŸ¥çœ‹åŒºåŸŸ ==========
    if st.session_state.get("show_history_detail") and st.session_state.get("viewing_history_id"):
        history_id = st.session_state.viewing_history_id
        # æŸ¥æ‰¾å¯¹åº”çš„å†å²è®°å½•
        history_item = None
        for item in st.session_state.session_history:
            if item.get("id") == history_id:
                history_item = item
                break
        
        if history_item:
            st.markdown("---")
            st.markdown(f"### ğŸ“œ å†å²è®°å½•è¯¦æƒ… #{history_id}")
            
            # å…³é—­æŒ‰é’®
            if st.button("âŒ å…³é—­è¯¦æƒ…", key="close_history_detail"):
                st.session_state.show_history_detail = False
                st.session_state.viewing_history_id = None
                st.rerun()
            
            col_info1, col_info2 = st.columns(2)
            with col_info1:
                st.markdown(f"**åŠŸèƒ½ç±»å‹ï¼š** {history_item.get('function_type', 'æœªçŸ¥')}")
            with col_info2:
                st.markdown(f"**ç”Ÿæˆæ—¶é—´ï¼š** {history_item.get('timestamp', 'æœªçŸ¥')}")
            
            # æ˜¾ç¤ºè¾“å…¥æ•°æ®
            with st.expander("ğŸ“¥ è¾“å…¥å†…å®¹", expanded=False):
                input_data = history_item.get("input_data", {})
                for key, value in input_data.items():
                    st.markdown(f"**{key}ï¼š**")
                    st.text(str(value)[:500] + ("..." if len(str(value)) > 500 else ""))
            
            # æ˜¾ç¤ºè¾“å‡ºæ•°æ®
            with st.expander("ğŸ“¤ è¾“å‡ºå†…å®¹", expanded=True):
                st.markdown(history_item.get("output_data", ""))
            
            # ä¸‹è½½æŒ‰é’®
            if history_item.get("download_data"):
                st.download_button(
                    label=f"ğŸ“¥ ä¸‹è½½ {history_item.get('download_filename', 'æ–‡ä»¶')}",
                    data=history_item["download_data"],
                    file_name=history_item.get("download_filename", "download.txt"),
                    mime=history_item.get("download_mime", "text/plain"),
                    key=f"history_download_{history_id}"
                )
            
            st.markdown("---")
    
    # åŠŸèƒ½é€‰æ‹©
    function_mode = st.selectbox(
        "ğŸ”§ åŠŸèƒ½é€‰æ‹©",
        options=["ç”Ÿæˆç­–åˆ’æ¡ˆ", "ä¼˜åŒ–ç­–åˆ’æ¡ˆ", "æ±‡æŠ¥åŠ©æ‰‹", "å‘¨æŠ¥åŠ©æ‰‹", "ç™½çš®ä¹¦åŠ©æ‰‹"],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„åŠŸèƒ½"
    )
    
    # æ ¹æ®åŠŸèƒ½æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„è¾“å…¥ç•Œé¢
    if function_mode == "ç”Ÿæˆç­–åˆ’æ¡ˆ":
        st.markdown("### ğŸ“ ç”Ÿæˆæ–°ç­–åˆ’æ¡ˆ")
        st.markdown("è¯·è¾“å…¥åŠŸèƒ½æè¿°ï¼ŒAIå°†ä¸ºæ‚¨ç”Ÿæˆå®Œæ•´çš„ç­–åˆ’æ¡ˆã€‚")
        
        user_input = st.text_area(
            "åŠŸèƒ½æè¿°",
            height=300,
            placeholder="è¯·è¯¦ç»†æè¿°æ‚¨è¦è®¾è®¡çš„æ¸¸æˆåŠŸèƒ½...\n\nä¾‹å¦‚ï¼š\nè®¾è®¡ä¸€ä¸ªæ¸¸æˆå†…çš„å¥½å‹ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ·»åŠ å¥½å‹ã€åˆ é™¤å¥½å‹ã€å¥½å‹åˆ—è¡¨å±•ç¤ºã€åœ¨çº¿çŠ¶æ€æ˜¾ç¤ºç­‰åŠŸèƒ½...",
            key="generate_input"
        )
        
        # ========== æ–‡ä»¶ä¸Šä¼ åŒºåŸŸï¼ˆè¾“å…¥æ¡†å³ä¸‹æ–¹ï¼‰==========
        if is_file_upload_supported():
            # åˆ›å»ºå¸ƒå±€ï¼šå·¦è¾¹æ˜¯ç©ºçš„å ä½ï¼Œå³è¾¹æ˜¯æ–‡ä»¶ä¸Šä¼ 
            upload_col1, upload_col2 = st.columns([2, 1])
            
            with upload_col2:
                uploaded_file = st.file_uploader(
                    "ğŸ“ ä¸Šä¼ é™„ä»¶",
                    type=SUPPORTED_FILE_TYPES,
                    help="ä¸Šä¼ å‚è€ƒæ–‡æ¡£ä¾›AIå‚è€ƒï¼ˆPDF/Word/TXT/MDï¼‰",
                    key="generate_file_uploader"
                )
                
                # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
                if uploaded_file is not None:
                    if "uploaded_file_content" not in st.session_state or \
                       st.session_state.get("uploaded_file_name") != uploaded_file.name:
                        with st.spinner("è§£æä¸­..."):
                            file_text = extract_text_from_file(uploaded_file)
                            st.session_state.uploaded_file_content = file_text
                            st.session_state.uploaded_file_name = uploaded_file.name
                    
                    # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯å’Œæ“ä½œ
                    st.caption(f"âœ… {uploaded_file.name}")
                    
                    # é¢„è§ˆå’Œæ¸…é™¤æŒ‰é’®æ”¾åœ¨ä¸€è¡Œ
                    btn_col1, btn_col2 = st.columns(2)
                    with btn_col1:
                        if st.button("ï¿½ï¸ é¢„è§ˆ", key="preview_gen", use_container_width=True):
                            st.session_state.show_preview_gen = not st.session_state.get("show_preview_gen", False)
                    with btn_col2:
                        if st.button("ğŸ—‘ï¸ æ¸…é™¤", key="clear_gen", use_container_width=True):
                            st.session_state.uploaded_file_content = ""
                            st.session_state.uploaded_file_name = ""
                            st.session_state.show_preview_gen = False
                            st.rerun()
                    
                    # é¢„è§ˆå†…å®¹
                    if st.session_state.get("show_preview_gen", False):
                        with st.expander("ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆ", expanded=True):
                            preview_text = st.session_state.uploaded_file_content
                            if len(preview_text) > 500:
                                st.text(preview_text[:500] + "\n\n... [å·²æˆªæ–­] ...")
                            else:
                                st.text(preview_text)
                else:
                    # æ¸…é™¤ä¹‹å‰çš„æ–‡ä»¶å†…å®¹
                    if "uploaded_file_content" in st.session_state and st.session_state.uploaded_file_content:
                        pass  # ä¿ç•™å·²ä¸Šä¼ çš„å†…å®¹ï¼Œé™¤éç”¨æˆ·æ‰‹åŠ¨æ¸…é™¤
            
            with upload_col1:
                # æ˜¾ç¤ºé™„ä»¶çŠ¶æ€æç¤º
                if st.session_state.get("uploaded_file_content"):
                    st.info(f"ğŸ“ å·²æ·»åŠ é™„ä»¶: **{st.session_state.get('uploaded_file_name', 'æœªçŸ¥æ–‡ä»¶')}**")
        else:
            # æ¨¡å‹ä¸æ”¯æŒæ–‡ä»¶ä¸Šä¼ æ—¶æ˜¾ç¤ºæç¤º
            st.caption("ğŸ’¡ å½“å‰æ¨¡å‹ä¸æ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼Œå¦‚éœ€ä¸Šä¼ é™„ä»¶è¯·åˆ‡æ¢è‡³æ”¯æŒçš„æ¨¡å‹")
        
        # åˆå§‹åŒ–è‡ªæ£€ç»“æœçš„session_state
        if "generated_check_result" not in st.session_state:
            st.session_state.generated_check_result = ""
        
        # ä½¿ç”¨session_stateè·Ÿè¸ªå½“å‰å¤„ç†é˜¶æ®µ
        if "current_stage" not in st.session_state:
            st.session_state.current_stage = "idle"  # idle, generating, checking, done
        
        if st.button("ğŸš€ ç”Ÿæˆç­–åˆ’æ¡ˆ", type="primary", disabled=st.session_state.is_processing):
            if not user_input.strip():
                st.error("è¯·è¾“å…¥åŠŸèƒ½æè¿°ï¼")
            else:
                st.session_state.is_processing = True
                st.session_state.should_stop = False  # é‡ç½®ä¸­æ­¢æ ‡å¿—
                st.session_state.generated_check_result = ""  # æ¸…ç©ºä¹‹å‰çš„æ£€æŸ¥ç»“æœ
                st.session_state.generated_prd = ""  # æ¸…ç©ºä¹‹å‰çš„ç»“æœ
                st.session_state.last_error = ""  # æ¸…ç©ºé”™è¯¯
                st.session_state.current_stage = "generating"
                st.session_state.generate_saved_to_history = False  # é‡ç½®å†å²ä¿å­˜æ ‡è®°
                # ä¿å­˜ç”¨æˆ·è¾“å…¥å’Œé™„ä»¶å†…å®¹åˆ°session_state
                st.session_state.saved_user_input = user_input
                st.session_state.saved_attachment_content = st.session_state.get("uploaded_file_content", "")
                st.session_state.saved_attachment_name = st.session_state.get("uploaded_file_name", "")
                st.rerun()  # è§¦å‘é‡æ–°æ¸²æŸ“
        
        # å¤„ç†ç”Ÿæˆé˜¶æ®µ
        if st.session_state.is_processing and st.session_state.current_stage == "generating":
            # ä»session_stateè·å–ä¿å­˜çš„è¾“å…¥
            user_input_saved = st.session_state.get("saved_user_input", user_input)
            attachment_content = st.session_state.get("saved_attachment_content", "")
            attachment_name = st.session_state.get("saved_attachment_name", "")
            
            # æµå¼ç”Ÿæˆç­–åˆ’æ¡ˆ
            st.markdown("### ğŸ“„ ç”Ÿæˆçš„ç­–åˆ’æ¡ˆ")
            
            # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
            col_status, col_stop = st.columns([4, 1])
            with col_status:
                st.markdown("**âœï¸ ç­–åˆ’é…¸å¥¶æ­£åœ¨æ’°å†™ç­–åˆ’æ¡ˆ...**")
            with col_stop:
                if st.button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", key="stop_generate", type="secondary"):
                    st.session_state.should_stop = True
                    st.warning("æ­£åœ¨ä¸­æ­¢...")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸï¼ˆå¯æŠ˜å ï¼‰
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            # çŠ¶æ€å’Œé”™è¯¯æ˜¾ç¤ºå®¹å™¨
            status_container = st.empty()
            
            # æ„å»ºæœ€ç»ˆçš„è¾“å…¥ï¼ˆåŒ…å«é™„ä»¶å†…å®¹ï¼‰
            final_input = user_input_saved
            if attachment_content:
                final_input = f"""ã€ç”¨æˆ·åŠŸèƒ½æè¿°ã€‘
{user_input_saved}

ã€é™„ä»¶å†…å®¹ã€‘ï¼ˆæ–‡ä»¶å: {attachment_name}ï¼‰
{attachment_content}

è¯·å‚è€ƒä»¥ä¸ŠåŠŸèƒ½æè¿°å’Œé™„ä»¶å†…å®¹ï¼Œç”Ÿæˆå®Œæ•´çš„ç­–åˆ’æ¡ˆã€‚"""
                st.info(f"ğŸ“ å·²åŒ…å«é™„ä»¶: {attachment_name}")
            
            # åˆ›å»ºå®¹å™¨ç”¨äºæµå¼æ˜¾ç¤º
            prd_container = st.empty()
            result, success, error = generate_prd(
                final_input, 
                use_stream=True, 
                container=prd_container,
                thinking_container=thinking_container,
                status_container=status_container
            )
            
            if success and result:
                st.session_state.generated_prd = result
                st.success("âœ… ç­–åˆ’æ¡ˆç”Ÿæˆå®Œæˆï¼")
                st.session_state.current_stage = "checking"
                st.rerun()  # è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
            elif error:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error}")
                st.session_state.is_processing = False
                st.session_state.current_stage = "idle"
            elif st.session_state.should_stop:
                st.warning("â¹ï¸ ç”Ÿæˆå·²ä¸­æ­¢")
                if result:  # å¦‚æœæœ‰éƒ¨åˆ†ç»“æœï¼Œä¿å­˜å®ƒ
                    st.session_state.generated_prd = result
                st.session_state.is_processing = False
                st.session_state.current_stage = "idle"
                st.session_state.should_stop = False
            else:
                st.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")
                st.session_state.is_processing = False
                st.session_state.current_stage = "idle"
        
        # å¤„ç†æ£€æŸ¥é˜¶æ®µ
        elif st.session_state.is_processing and st.session_state.current_stage == "checking":
            # æ˜¾ç¤ºå·²ç”Ÿæˆçš„ç­–åˆ’æ¡ˆ
            st.markdown("### ğŸ“„ ç”Ÿæˆçš„ç­–åˆ’æ¡ˆ")
            st.markdown(st.session_state.generated_prd)
            st.success("âœ… ç­–åˆ’æ¡ˆç”Ÿæˆå®Œæˆï¼")
            
            # AIè‡ªæ£€ - æµå¼è¾“å‡º
            st.markdown("### ğŸ” AIå¤æ£€æ¸…å•æ£€æŸ¥ç»“æœ")
            
            # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
            col_status, col_stop = st.columns([4, 1])
            with col_status:
                st.markdown("**ğŸ” AIæ­£åœ¨è¿›è¡Œå¤æ£€æ¸…å•æ£€æŸ¥...**")
            with col_stop:
                if st.button("â¹ï¸ ä¸­æ­¢æ£€æŸ¥", key="stop_check", type="secondary"):
                    st.session_state.should_stop = True
                    st.warning("æ­£åœ¨ä¸­æ­¢...")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            # çŠ¶æ€å’Œé”™è¯¯æ˜¾ç¤ºå®¹å™¨
            status_container = st.empty()
            
            check_container = st.empty()
            check_result, success, error = ai_self_check(
                st.session_state.generated_prd, 
                use_stream=True, 
                container=check_container,
                thinking_container=thinking_container,
                status_container=status_container
            )
            
            if success and check_result:
                st.session_state.generated_check_result = check_result
                st.success("âœ… å¤æ£€å®Œæˆï¼")
            elif error:
                st.error(f"âŒ å¤æ£€å¤±è´¥: {error}")
            
            st.session_state.is_processing = False
            st.session_state.current_stage = "done"
            st.session_state.should_stop = False
            st.rerun()  # åˆ·æ–°ä»¥æ˜¾ç¤ºæœ€ç»ˆç»“æœå’Œä¸‹è½½æŒ‰é’®
        
        # æ˜¾ç¤ºå·²ä¿å­˜çš„ç”Ÿæˆç»“æœï¼ˆéå¤„ç†ä¸­çŠ¶æ€ï¼‰
        if st.session_state.generated_prd and not st.session_state.is_processing:
            st.markdown("### ğŸ“„ ç”Ÿæˆçš„ç­–åˆ’æ¡ˆ")
            st.markdown(st.session_state.generated_prd)
            
            # æ˜¾ç¤ºAIè‡ªæ£€ç»“æœ
            if st.session_state.generated_check_result:
                st.markdown("### ğŸ” AIå¤æ£€æ¸…å•æ£€æŸ¥ç»“æœ")
                with st.expander("æŸ¥çœ‹è¯¦ç»†æ£€æŸ¥ç»“æœ", expanded=True):
                    st.markdown(st.session_state.generated_check_result)
            
            st.markdown(CHECKLIST)
            
            # ä¸‹è½½æŒ‰é’® - Excelæ ¼å¼
            excel_data = create_excel_file(
                st.session_state.generated_prd,
                st.session_state.generated_check_result
            )
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç­–åˆ’æ¡ˆ (Excel)",
                data=excel_data,
                file_name="ç­–åˆ’æ¡ˆ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # ä¿å­˜åˆ°ä¼šè¯å†å²ï¼ˆä»…åœ¨é¦–æ¬¡å®Œæˆæ—¶ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
            if st.session_state.get("current_stage") == "done" and not st.session_state.get("generate_saved_to_history"):
                add_to_history(
                    function_type="ç”Ÿæˆç­–åˆ’æ¡ˆ",
                    input_data={"åŠŸèƒ½æè¿°": st.session_state.get("saved_user_input", "")},
                    output_data=st.session_state.generated_prd,
                    download_data=excel_data,
                    download_filename="ç­–åˆ’æ¡ˆ.xlsx",
                    download_mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                st.session_state.generate_saved_to_history = True
            
            # ========== å¤šè½®å¯¹è¯åŒºåŸŸ ==========
            st.markdown("---")
            st.markdown("### ğŸ’¬ ç»§ç»­å¯¹è¯")
            st.caption("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®æˆ–è¦æ±‚ä¿®æ”¹ï¼ŒAIå°†åŸºäºå·²ç”Ÿæˆçš„ç­–åˆ’æ¡ˆè¿›è¡Œå›ç­”ã€‚")
            
            # åˆå§‹åŒ–å¯¹è¯å†å²
            chat_key = "generate_prd_chat"
            init_chat_history(chat_key)
            
            # æ˜¾ç¤ºå¯¹è¯å†å²
            chat_history = get_chat_history(chat_key)
            if chat_history:
                for msg in chat_history:
                    if msg["role"] == "user":
                        st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                        st.info(msg["content"])
                    else:
                        st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                        st.markdown(msg["content"])
            
            # å¯¹è¯è¾“å…¥
            chat_col1, chat_col2, chat_col3 = st.columns([6, 1, 1])
            with chat_col1:
                chat_input = st.text_input(
                    "è¿½é—®æˆ–ä¿®æ”¹è¦æ±‚",
                    placeholder="ä¾‹å¦‚ï¼šè¯·è¯¦ç»†è¯´æ˜ç¬¬3ç« çš„éªŒæ”¶æ ‡å‡†...",
                    key="generate_chat_input",
                    label_visibility="collapsed"
                )
            with chat_col2:
                chat_send = st.button("å‘é€", key="generate_chat_send", type="primary", use_container_width=True)
            with chat_col3:
                if st.button("æ¸…ç©º", key="generate_chat_clear", use_container_width=True):
                    clear_chat_history(chat_key)
                    st.rerun()
            
            # å¤„ç†å¯¹è¯
            if chat_send and chat_input.strip():
                add_chat_message(chat_key, "user", chat_input)
                
                # æ„å»ºä¸Šä¸‹æ–‡
                function_context = f"""ã€å·²ç”Ÿæˆçš„ç­–åˆ’æ¡ˆã€‘
{st.session_state.generated_prd}"""
                
                history_context = build_chat_context(chat_key, GENERATE_PRD_SYSTEM_PROMPT)
                full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{chat_input}

è¯·åŸºäºä»¥ä¸Šç­–åˆ’æ¡ˆå’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ä¿®æ”¹ç­–åˆ’æ¡ˆï¼Œè¯·è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹ã€‚"""
                
                with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                    response_container = st.empty()
                    full_response = ""
                    for chunk in call_gemini_stream(full_prompt, GENERATE_PRD_SYSTEM_PROMPT):
                        if chunk["type"] == "text":
                            full_response += chunk["content"]
                            response_container.markdown(full_response + "â–Œ")
                        elif chunk["type"] == "error":
                            st.error(f"ç”Ÿæˆå¤±è´¥: {chunk['content']}")
                            break
                    
                    if full_response:
                        response_container.markdown(full_response)
                        add_chat_message(chat_key, "assistant", full_response)
                        st.rerun()
    
    elif function_mode == "ä¼˜åŒ–ç­–åˆ’æ¡ˆ":
        st.markdown("### ğŸ”„ ä¼˜åŒ–ç°æœ‰ç­–åˆ’æ¡ˆ")
        st.markdown("è¯·è¾“å…¥åŸç­–åˆ’æ¡ˆå’Œä¿®æ”¹æ„è§ï¼ŒAIå°†é€šè¿‡å¤šè½®è¿­ä»£è¿›è¡Œä¼˜åŒ–ã€‚")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            old_prd = st.text_area(
                "åŸç­–åˆ’æ¡ˆ",
                height=400,
                placeholder="è¯·ç²˜è´´éœ€è¦ä¼˜åŒ–çš„ç­–åˆ’æ¡ˆå†…å®¹...",
                key="optimize_input"
            )
            
            # ========== æ–‡ä»¶ä¸Šä¼ åŒºåŸŸï¼ˆè¾“å…¥æ¡†å³ä¸‹æ–¹ï¼‰==========
            if is_file_upload_supported():
                # åˆ›å»ºå¸ƒå±€ï¼šå·¦è¾¹æ˜¯çŠ¶æ€æç¤ºï¼Œå³è¾¹æ˜¯æ–‡ä»¶ä¸Šä¼ 
                opt_upload_col1, opt_upload_col2 = st.columns([2, 1])
                
                with opt_upload_col2:
                    uploaded_file_opt = st.file_uploader(
                        "ğŸ“ ä¸Šä¼ é™„ä»¶",
                        type=SUPPORTED_FILE_TYPES,
                        help="ä¸Šä¼ å‚è€ƒæ–‡æ¡£ä¾›AIå‚è€ƒï¼ˆPDF/Word/TXT/MDï¼‰",
                        key="optimize_file_uploader"
                    )
                    
                    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
                    if uploaded_file_opt is not None:
                        if "uploaded_file_content" not in st.session_state or \
                           st.session_state.get("uploaded_file_name") != uploaded_file_opt.name:
                            with st.spinner("è§£æä¸­..."):
                                file_text = extract_text_from_file(uploaded_file_opt)
                                st.session_state.uploaded_file_content = file_text
                                st.session_state.uploaded_file_name = uploaded_file_opt.name
                        
                        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯å’Œæ“ä½œ
                        st.caption(f"âœ… {uploaded_file_opt.name}")
                        
                        # é¢„è§ˆå’Œæ¸…é™¤æŒ‰é’®æ”¾åœ¨ä¸€è¡Œ
                        opt_btn_col1, opt_btn_col2 = st.columns(2)
                        with opt_btn_col1:
                            if st.button("ğŸ‘ï¸ é¢„è§ˆ", key="preview_opt", use_container_width=True):
                                st.session_state.show_preview_opt = not st.session_state.get("show_preview_opt", False)
                        with opt_btn_col2:
                            if st.button("ğŸ—‘ï¸ æ¸…é™¤", key="clear_opt", use_container_width=True):
                                st.session_state.uploaded_file_content = ""
                                st.session_state.uploaded_file_name = ""
                                st.session_state.show_preview_opt = False
                                st.rerun()
                        
                        # é¢„è§ˆå†…å®¹
                        if st.session_state.get("show_preview_opt", False):
                            with st.expander("ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆ", expanded=True):
                                preview_text = st.session_state.uploaded_file_content
                                if len(preview_text) > 500:
                                    st.text(preview_text[:500] + "\n\n... [å·²æˆªæ–­] ...")
                                else:
                                    st.text(preview_text)
                
                with opt_upload_col1:
                    # æ˜¾ç¤ºé™„ä»¶çŠ¶æ€æç¤º
                    if st.session_state.get("uploaded_file_content"):
                        st.info(f"ğŸ“ å·²æ·»åŠ é™„ä»¶: **{st.session_state.get('uploaded_file_name', 'æœªçŸ¥æ–‡ä»¶')}**")
            else:
                # æ¨¡å‹ä¸æ”¯æŒæ–‡ä»¶ä¸Šä¼ æ—¶æ˜¾ç¤ºæç¤º
                st.caption("ğŸ’¡ å½“å‰æ¨¡å‹ä¸æ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼Œå¦‚éœ€ä¸Šä¼ é™„ä»¶è¯·åˆ‡æ¢è‡³æ”¯æŒçš„æ¨¡å‹")
        
        with col2:
            feedback = st.text_area(
                "ä¿®æ”¹æ„è§ï¼ˆå¯é€‰ï¼‰",
                height=200,
                placeholder="è¯·è¾“å…¥æ‚¨çš„ä¿®æ”¹æ„è§æˆ–å…³æ³¨ç‚¹...",
                key="feedback_input"
            )
            
            max_iterations = st.number_input(
                "è¿­ä»£è½®æ¬¡",
                min_value=1,
                max_value=10,
                value=3,
                help="è®¾ç½®Reflectionå¾ªç¯çš„è¿­ä»£æ¬¡æ•°ï¼ˆ1-10è½®ï¼‰"
            )
        
        # ä½¿ç”¨session_stateè·Ÿè¸ªä¼˜åŒ–é˜¶æ®µ
        if "optimize_stage" not in st.session_state:
            st.session_state.optimize_stage = "idle"  # idle, initial, reflection, checking, done
        if "initial_fixed_prd" not in st.session_state:
            st.session_state.initial_fixed_prd = ""
        if "saved_old_prd" not in st.session_state:
            st.session_state.saved_old_prd = ""
        if "saved_feedback" not in st.session_state:
            st.session_state.saved_feedback = ""
        if "saved_max_iterations" not in st.session_state:
            st.session_state.saved_max_iterations = 3
        
        if st.button("ğŸ”„ å¼€å§‹ä¼˜åŒ–", type="primary", disabled=st.session_state.is_processing):
            if not old_prd.strip():
                st.error("è¯·è¾“å…¥åŸç­–åˆ’æ¡ˆï¼")
            else:
                st.session_state.is_processing = True
                st.session_state.should_stop = False  # é‡ç½®ä¸­æ­¢æ ‡å¿—
                st.session_state.last_error = ""  # æ¸…ç©ºé”™è¯¯
                st.session_state.optimized_prd = ""
                st.session_state.optimized_check_result = ""
                st.session_state.initial_fixed_prd = ""
                st.session_state.saved_old_prd = old_prd
                st.session_state.saved_feedback = feedback
                st.session_state.saved_max_iterations = max_iterations
                st.session_state.optimize_saved_to_history = False  # é‡ç½®å†å²ä¿å­˜æ ‡è®°
                # ä¿å­˜é™„ä»¶å†…å®¹
                st.session_state.saved_optimize_attachment = st.session_state.get("uploaded_file_content", "")
                st.session_state.saved_optimize_attachment_name = st.session_state.get("uploaded_file_name", "")
                st.session_state.optimize_stage = "initial"
                st.rerun()  # è§¦å‘é‡æ–°æ¸²æŸ“
        
        # å¤„ç†åˆå§‹ä¿®æ­£é˜¶æ®µ
        if st.session_state.is_processing and st.session_state.optimize_stage == "initial":
            st.markdown("### ğŸ“Œ Step 1: åˆå§‹ä¿®æ­£")
            
            # æ˜¾ç¤ºé™„ä»¶ä½¿ç”¨ä¿¡æ¯
            optimize_attachment = st.session_state.get("saved_optimize_attachment", "")
            optimize_attachment_name = st.session_state.get("saved_optimize_attachment_name", "")
            if optimize_attachment:
                st.info(f"ğŸ“ å‚è€ƒé™„ä»¶: {optimize_attachment_name}")
            
            # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
            col_status, col_stop = st.columns([4, 1])
            with col_status:
                st.markdown("**âœï¸ æ­£åœ¨è¿›è¡Œåˆå§‹ä¿®æ­£...**")
            with col_stop:
                if st.button("â¹ï¸ ä¸­æ­¢", key="stop_initial", type="secondary"):
                    st.session_state.should_stop = True
                    st.warning("æ­£åœ¨ä¸­æ­¢...")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            # çŠ¶æ€å’Œé”™è¯¯æ˜¾ç¤ºå®¹å™¨
            status_container = st.empty()
            
            # æ„å»ºåŒ…å«é™„ä»¶çš„feedback
            final_feedback = st.session_state.saved_feedback
            if optimize_attachment:
                final_feedback = f"""{st.session_state.saved_feedback if st.session_state.saved_feedback else "æ— ç‰¹åˆ«æ„è§"}

ã€é™„ä»¶å†…å®¹å‚è€ƒã€‘ï¼ˆæ–‡ä»¶å: {optimize_attachment_name}ï¼‰
{optimize_attachment}"""
            
            initial_container = st.empty()
            initial_fixed, success, error = optimize_prd_initial(
                st.session_state.saved_old_prd, 
                final_feedback,
                use_stream=True, 
                container=initial_container,
                thinking_container=thinking_container,
                status_container=status_container
            )
            
            if success and initial_fixed:
                st.session_state.initial_fixed_prd = initial_fixed
                st.success("åˆå§‹ä¿®æ­£å®Œæˆï¼")
                st.session_state.optimize_stage = "reflection"
                st.rerun()
            elif error:
                st.error(f"âŒ åˆå§‹ä¿®æ­£å¤±è´¥: {error}")
                st.session_state.is_processing = False
                st.session_state.optimize_stage = "idle"
            elif st.session_state.should_stop:
                st.warning("â¹ï¸ å·²ä¸­æ­¢")
                st.session_state.is_processing = False
                st.session_state.optimize_stage = "idle"
                st.session_state.should_stop = False
            else:
                st.error("åˆå§‹ä¿®æ­£å¤±è´¥ï¼Œè¯·é‡è¯•")
                st.session_state.is_processing = False
                st.session_state.optimize_stage = "idle"
        
        # å¤„ç†Reflectionå¾ªç¯é˜¶æ®µ
        elif st.session_state.is_processing and st.session_state.optimize_stage == "reflection":
            # æ˜¾ç¤ºå·²å®Œæˆçš„åˆå§‹ä¿®æ­£
            st.markdown("### ğŸ“Œ Step 1: åˆå§‹ä¿®æ­£")
            with st.expander("æŸ¥çœ‹åˆå§‹ä¿®æ­£ç»“æœ", expanded=False):
                st.markdown(st.session_state.initial_fixed_prd)
            st.success("åˆå§‹ä¿®æ­£å®Œæˆï¼")
            st.markdown("---")
            
            # Reflectionå¾ªç¯
            st.markdown("### ğŸ” Step 2: Reflection å¾ªç¯ä¼˜åŒ–")
            final_prd, was_stopped = reflection_loop(st.session_state.initial_fixed_prd, st.session_state.saved_max_iterations)
            
            st.session_state.optimized_prd = final_prd
            
            if was_stopped:
                st.warning("â¹ï¸ è¿­ä»£å·²ä¸­æ­¢ï¼Œå°†ä½¿ç”¨å½“å‰ç‰ˆæœ¬è¿›è¡Œå¤æ£€")
                st.session_state.should_stop = False
            
            st.session_state.optimize_stage = "checking"
            st.rerun()
        
        # å¤„ç†æœ€ç»ˆæ£€æŸ¥é˜¶æ®µ
        elif st.session_state.is_processing and st.session_state.optimize_stage == "checking":
            # æ˜¾ç¤ºä¹‹å‰çš„æ­¥éª¤
            st.markdown("### ğŸ“Œ Step 1: åˆå§‹ä¿®æ­£")
            st.success("åˆå§‹ä¿®æ­£å®Œæˆï¼")
            st.markdown("---")
            
            st.markdown("### ğŸ” Step 2: Reflection å¾ªç¯ä¼˜åŒ–")
            st.success(f"å®Œæˆ {st.session_state.saved_max_iterations} è½®è¿­ä»£ä¼˜åŒ–ï¼")
            st.markdown("---")
            
            # AIè‡ªæ£€ - æµå¼è¾“å‡º
            st.markdown("### ğŸ” Step 3: AIå¤æ£€æ¸…å•æ£€æŸ¥")
            
            # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
            col_status, col_stop = st.columns([4, 1])
            with col_status:
                st.markdown("**ğŸ” AIæ­£åœ¨è¿›è¡Œæœ€ç»ˆå¤æ£€æ¸…å•æ£€æŸ¥...**")
            with col_stop:
                if st.button("â¹ï¸ ä¸­æ­¢æ£€æŸ¥", key="stop_final_check", type="secondary"):
                    st.session_state.should_stop = True
                    st.warning("æ­£åœ¨ä¸­æ­¢...")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            status_container = st.empty()
            check_container = st.empty()
            
            check_result, success, error = ai_self_check(
                st.session_state.optimized_prd, 
                use_stream=True, 
                container=check_container,
                thinking_container=thinking_container,
                status_container=status_container
            )
            
            if success and check_result:
                st.session_state.optimized_check_result = check_result
                st.success("âœ… å¤æ£€å®Œæˆï¼")
            elif error:
                st.error(f"âŒ å¤æ£€å¤±è´¥: {error}")
                st.session_state.optimized_check_result = ""
            else:
                st.session_state.optimized_check_result = ""
            
            st.session_state.is_processing = False
            st.session_state.optimize_stage = "done"
            st.session_state.should_stop = False
            st.success("âœ… ç­–åˆ’æ¡ˆä¼˜åŒ–å®Œæˆï¼")
            st.rerun()  # åˆ·æ–°ä»¥æ˜¾ç¤ºæœ€ç»ˆç»“æœå’Œä¸‹è½½æŒ‰é’®
        
        # åˆå§‹åŒ–ä¼˜åŒ–è‡ªæ£€ç»“æœçš„session_state
        if "optimized_check_result" not in st.session_state:
            st.session_state.optimized_check_result = ""
        
        # æ˜¾ç¤ºå·²ä¿å­˜çš„ä¼˜åŒ–ç»“æœï¼ˆéå¤„ç†ä¸­çŠ¶æ€ï¼‰
        if st.session_state.optimized_prd and not st.session_state.is_processing:
            st.markdown("### ğŸ“„ æœ€ç»ˆä¼˜åŒ–åçš„ç­–åˆ’æ¡ˆ")
            st.markdown(st.session_state.optimized_prd)
            
            # æ˜¾ç¤ºAIè‡ªæ£€ç»“æœ
            if st.session_state.optimized_check_result:
                st.markdown("### ğŸ” AIå¤æ£€æ¸…å•æ£€æŸ¥ç»“æœ")
                with st.expander("æŸ¥çœ‹è¯¦ç»†æ£€æŸ¥ç»“æœ", expanded=True):
                    st.markdown(st.session_state.optimized_check_result)
            
            st.markdown(CHECKLIST)
            
            # ä¸‹è½½æŒ‰é’® - Excelæ ¼å¼
            excel_data = create_excel_file(
                st.session_state.optimized_prd,
                st.session_state.optimized_check_result
            )
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ä¼˜åŒ–åçš„ç­–åˆ’æ¡ˆ (Excel)",
                data=excel_data,
                file_name="ä¼˜åŒ–åçš„ç­–åˆ’æ¡ˆ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # ä¿å­˜åˆ°ä¼šè¯å†å²ï¼ˆä»…åœ¨é¦–æ¬¡å®Œæˆæ—¶ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
            if st.session_state.get("optimize_stage") == "done" and not st.session_state.get("optimize_saved_to_history"):
                add_to_history(
                    function_type="ä¼˜åŒ–ç­–åˆ’æ¡ˆ",
                    input_data={
                        "åŸç­–åˆ’æ¡ˆ": st.session_state.get("saved_old_prd", "")[:200] + "...",
                        "ä¿®æ”¹æ„è§": st.session_state.get("saved_feedback", ""),
                        "è¿­ä»£è½®æ¬¡": st.session_state.get("saved_max_iterations", 3)
                    },
                    output_data=st.session_state.optimized_prd,
                    download_data=excel_data,
                    download_filename="ä¼˜åŒ–åçš„ç­–åˆ’æ¡ˆ.xlsx",
                    download_mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                st.session_state.optimize_saved_to_history = True
            
            # ========== å¤šè½®å¯¹è¯åŒºåŸŸ ==========
            st.markdown("---")
            st.markdown("### ğŸ’¬ ç»§ç»­å¯¹è¯")
            st.caption("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®æˆ–è¦æ±‚ä¿®æ”¹ï¼ŒAIå°†åŸºäºä¼˜åŒ–åçš„ç­–åˆ’æ¡ˆè¿›è¡Œå›ç­”ã€‚")
            
            # åˆå§‹åŒ–å¯¹è¯å†å²
            chat_key = "optimize_prd_chat"
            init_chat_history(chat_key)
            
            # æ˜¾ç¤ºå¯¹è¯å†å²
            chat_history = get_chat_history(chat_key)
            if chat_history:
                for msg in chat_history:
                    if msg["role"] == "user":
                        st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                        st.info(msg["content"])
                    else:
                        st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                        st.markdown(msg["content"])
            
            # å¯¹è¯è¾“å…¥
            opt_chat_col1, opt_chat_col2, opt_chat_col3 = st.columns([6, 1, 1])
            with opt_chat_col1:
                opt_chat_input = st.text_input(
                    "è¿½é—®æˆ–ä¿®æ”¹è¦æ±‚",
                    placeholder="ä¾‹å¦‚ï¼šè¯·è¡¥å……æŠ€æœ¯ä¾èµ–éƒ¨åˆ†çš„ç»†èŠ‚...",
                    key="optimize_chat_input",
                    label_visibility="collapsed"
                )
            with opt_chat_col2:
                opt_chat_send = st.button("å‘é€", key="optimize_chat_send", type="primary", use_container_width=True)
            with opt_chat_col3:
                if st.button("æ¸…ç©º", key="optimize_chat_clear", use_container_width=True):
                    clear_chat_history(chat_key)
                    st.rerun()
            
            # å¤„ç†å¯¹è¯
            if opt_chat_send and opt_chat_input.strip():
                add_chat_message(chat_key, "user", opt_chat_input)
                
                # æ„å»ºä¸Šä¸‹æ–‡
                function_context = f"""ã€ä¼˜åŒ–åçš„ç­–åˆ’æ¡ˆã€‘
{st.session_state.optimized_prd}"""
                
                history_context = build_chat_context(chat_key, INITIAL_FIX_SYSTEM_PROMPT)
                full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{opt_chat_input}

è¯·åŸºäºä»¥ä¸Šç­–åˆ’æ¡ˆå’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ä¿®æ”¹ç­–åˆ’æ¡ˆï¼Œè¯·è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹ã€‚"""
                
                with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                    response_container = st.empty()
                    full_response = ""
                    for chunk in call_gemini_stream(full_prompt, INITIAL_FIX_SYSTEM_PROMPT):
                        if chunk["type"] == "text":
                            full_response += chunk["content"]
                            response_container.markdown(full_response + "â–Œ")
                        elif chunk["type"] == "error":
                            st.error(f"ç”Ÿæˆå¤±è´¥: {chunk['content']}")
                            break
                    
                    if full_response:
                        response_container.markdown(full_response)
                        add_chat_message(chat_key, "assistant", full_response)
                        st.rerun()
    
    # ========== æ±‡æŠ¥åŠ©æ‰‹åŠŸèƒ½ ==========
    elif function_mode == "æ±‡æŠ¥åŠ©æ‰‹":
        st.markdown("### ğŸ“Š æ±‡æŠ¥åŠ©æ‰‹")
        st.markdown("å°†ç¢ç‰‡åŒ–çš„å·¥ä½œä¿¡æ¯è½¬åŒ–ä¸ºç»“æ„åŒ–çš„æ±‡æŠ¥æ–‡æ¡ˆï¼Œç”¨äºå‘é¢†å¯¼åŒæ­¥å·¥ä½œäº‹é¡¹ã€‚")
        
        # ä¸‰ä¸ªç‹¬ç«‹çš„è¾“å…¥æ¡†
        col1, col2 = st.columns([1, 1])
        
        with col1:
            current_problem = st.text_area(
                "ğŸ“Œ å½“å‰é—®é¢˜ (Current Problem)",
                height=150,
                placeholder="æè¿°å½“å‰é‡åˆ°çš„é—®é¢˜æˆ–èƒŒæ™¯...\n\nä¾‹å¦‚ï¼š\nå½“å‰ç”¨æˆ·åé¦ˆæ¸¸æˆå†…å¥½å‹æ·»åŠ æµç¨‹ç¹çï¼Œéœ€è¦æ‰‹åŠ¨è¾“å…¥IDï¼Œä¸”æ²¡æœ‰æ¨èå¥½å‹åŠŸèƒ½...",
                key="report_problem"
            )
            
            expected_result = st.text_area(
                "ğŸ¯ é¢„æœŸç»“æœ (Expected Result)",
                height=150,
                placeholder="æè¿°æœŸæœ›è¾¾æˆçš„æ•ˆæœ...\n\nä¾‹å¦‚ï¼š\nå¥½å‹æ·»åŠ æˆåŠŸç‡æå‡30%ï¼Œç”¨æˆ·å¥½å‹æ•°é‡å¹³å‡å¢åŠ 2ä¸ª...",
                key="report_result"
            )
        
        with col2:
            solution = st.text_area(
                "ğŸ’¡ è§£å†³æ–¹æ¡ˆ (Solution)",
                height=332,
                placeholder="æè¿°æ‚¨çš„è§£å†³æ–¹æ¡ˆæˆ–è®¡åˆ’é‡‡å–çš„æªæ–½...\n\nä¾‹å¦‚ï¼š\n1. æ–°å¢ã€Œå¯èƒ½è®¤è¯†çš„äººã€æ¨èåˆ—è¡¨\n2. æ”¯æŒé€šè¿‡æ¸¸æˆå†…æ˜µç§°æœç´¢\n3. æ·»åŠ å¥½å‹åè‡ªåŠ¨å‘é€ä¸€æ¡æ‹›å‘¼è¯­...",
                key="report_solution"
            )
        
        # åˆå§‹åŒ–æ±‡æŠ¥åŠ©æ‰‹ç›¸å…³çš„session_state
        if "generated_report" not in st.session_state:
            st.session_state.generated_report = ""
        if "report_processing" not in st.session_state:
            st.session_state.report_processing = False
        
        # ç”ŸæˆæŒ‰é’®
        if st.button("ğŸ“ ç”Ÿæˆæ±‡æŠ¥", type="primary", disabled=st.session_state.report_processing):
            # éªŒè¯è¾“å…¥
            if not current_problem.strip():
                st.error("è¯·å¡«å†™ã€å½“å‰é—®é¢˜ã€‘ï¼")
            elif not solution.strip():
                st.error("è¯·å¡«å†™ã€è§£å†³æ–¹æ¡ˆã€‘ï¼")
            elif not expected_result.strip():
                st.error("è¯·å¡«å†™ã€é¢„æœŸç»“æœã€‘ï¼")
            else:
                st.session_state.report_processing = True
                st.session_state.should_stop = False
                st.session_state.generated_report = ""
                st.session_state.report_saved_to_history = False  # é‡ç½®å†å²ä¿å­˜æ ‡è®°
                st.rerun()
        
        # å¤„ç†ç”Ÿæˆé˜¶æ®µ
        if st.session_state.report_processing:
            # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
            col_status, col_stop = st.columns([4, 1])
            with col_status:
                st.markdown("**âœï¸ æ­£åœ¨ç”Ÿæˆæ±‡æŠ¥æ–‡æ¡ˆ...**")
            with col_stop:
                if st.button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", key="stop_report", type="secondary"):
                    st.session_state.should_stop = True
                    st.warning("æ­£åœ¨ä¸­æ­¢...")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            # è¾“å‡ºå®¹å™¨
            output_container = st.empty()
            
            # æ„å»ºPrompt
            user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œæ’°å†™ä¸€ä»½ç»™é¢†å¯¼çš„å·¥ä½œæ±‡æŠ¥æ–‡æ¡ˆï¼š

ã€å½“å‰é—®é¢˜ã€‘
{current_problem}

ã€è§£å†³æ–¹æ¡ˆã€‘
{solution}

ã€é¢„æœŸç»“æœã€‘
{expected_result}

è¯·æŒ‰ç…§æ¨¡æ¿æ ¼å¼è¾“å‡ºæ±‡æŠ¥æ–‡æ¡ˆã€‚"""
            
            # è°ƒç”¨Gemini APIï¼ˆæµå¼ï¼‰
            full_response = ""
            thinking_content = ""
            was_stopped = False
            has_error = False
            error_message = ""
            
            for chunk in call_gemini_stream(user_prompt, REPORT_ASSISTANT_SYSTEM_PROMPT, thinking_container):
                if st.session_state.should_stop:
                    was_stopped = True
                    break
                
                if chunk["type"] == "text":
                    full_response += chunk["content"]
                    output_container.markdown(full_response + "â–Œ")
                elif chunk["type"] == "thinking":
                    thinking_content += chunk["content"]
                    with thinking_expander:
                        thinking_container.markdown(thinking_content)
                elif chunk["type"] == "error":
                    has_error = True
                    error_message = chunk["content"]
                    break
                elif chunk["type"] == "retry":
                    st.info(chunk["content"])
            
            # ç§»é™¤å…‰æ ‡
            if full_response:
                output_container.markdown(full_response)
            
            # å¤„ç†ç»“æœ
            if has_error:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error_message}")
            elif was_stopped:
                st.warning("âš ï¸ ç”Ÿæˆå·²ä¸­æ­¢")
                if full_response:
                    st.session_state.generated_report = full_response
            else:
                st.success("âœ… æ±‡æŠ¥æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼")
                st.session_state.generated_report = full_response
            
            st.session_state.report_processing = False
            st.session_state.should_stop = False
            st.rerun()
        
        # æ˜¾ç¤ºå·²ç”Ÿæˆçš„æ±‡æŠ¥ï¼ˆéå¤„ç†ä¸­çŠ¶æ€ï¼‰
        if st.session_state.generated_report and not st.session_state.report_processing:
            st.markdown("### ğŸ“„ ç”Ÿæˆçš„æ±‡æŠ¥æ–‡æ¡ˆ")
            st.markdown(st.session_state.generated_report)
            
            # å¤åˆ¶æŒ‰é’®ï¼ˆä½¿ç”¨ä¸‹è½½æŒ‰é’®æ¨¡æ‹Ÿï¼‰
            st.download_button(
                label="ğŸ“‹ ä¸‹è½½æ±‡æŠ¥æ–‡æ¡ˆ (TXT)",
                data=st.session_state.generated_report,
                file_name="å·¥ä½œæ±‡æŠ¥.txt",
                mime="text/plain"
            )
            
            # ä¿å­˜åˆ°ä¼šè¯å†å²ï¼ˆä»…åœ¨é¦–æ¬¡å®Œæˆæ—¶ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
            if not st.session_state.get("report_saved_to_history"):
                add_to_history(
                    function_type="æ±‡æŠ¥åŠ©æ‰‹",
                    input_data={
                        "å½“å‰é—®é¢˜": st.session_state.get("report_problem", ""),
                        "è§£å†³æ–¹æ¡ˆ": st.session_state.get("report_solution", ""),
                        "é¢„æœŸç»“æœ": st.session_state.get("report_result", "")
                    },
                    output_data=st.session_state.generated_report,
                    download_data=st.session_state.generated_report.encode("utf-8"),
                    download_filename="å·¥ä½œæ±‡æŠ¥.txt",
                    download_mime="text/plain"
                )
                st.session_state.report_saved_to_history = True
            
            # ========== å¤šè½®å¯¹è¯åŒºåŸŸ ==========
            st.markdown("---")
            st.markdown("### ğŸ’¬ ç»§ç»­å¯¹è¯")
            st.caption("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®æˆ–è¦æ±‚ä¿®æ”¹ï¼ŒAIå°†åŸºäºå·²ç”Ÿæˆçš„æ±‡æŠ¥æ–‡æ¡ˆè¿›è¡Œå›ç­”ã€‚")
            
            # åˆå§‹åŒ–å¯¹è¯å†å²
            chat_key = "report_chat"
            init_chat_history(chat_key)
            
            # æ˜¾ç¤ºå¯¹è¯å†å²
            chat_history = get_chat_history(chat_key)
            if chat_history:
                for msg in chat_history:
                    if msg["role"] == "user":
                        st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                        st.info(msg["content"])
                    else:
                        st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                        st.markdown(msg["content"])
            
            # å¯¹è¯è¾“å…¥
            report_chat_col1, report_chat_col2, report_chat_col3 = st.columns([6, 1, 1])
            with report_chat_col1:
                report_chat_input = st.text_input(
                    "è¿½é—®æˆ–ä¿®æ”¹è¦æ±‚",
                    placeholder="ä¾‹å¦‚ï¼šè¯·æŠŠè§£å†³æ–¹æ¡ˆå†™å¾—æ›´è¯¦ç»†ä¸€äº›...",
                    key="report_chat_input",
                    label_visibility="collapsed"
                )
            with report_chat_col2:
                report_chat_send = st.button("å‘é€", key="report_chat_send", type="primary", use_container_width=True)
            with report_chat_col3:
                if st.button("æ¸…ç©º", key="report_chat_clear", use_container_width=True):
                    clear_chat_history(chat_key)
                    st.rerun()
            
            # å¤„ç†å¯¹è¯
            if report_chat_send and report_chat_input.strip():
                add_chat_message(chat_key, "user", report_chat_input)
                
                # æ„å»ºä¸Šä¸‹æ–‡
                function_context = f"""ã€å·²ç”Ÿæˆçš„æ±‡æŠ¥æ–‡æ¡ˆã€‘
{st.session_state.generated_report}"""
                
                history_context = build_chat_context(chat_key, REPORT_ASSISTANT_SYSTEM_PROMPT)
                full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{report_chat_input}

è¯·åŸºäºä»¥ä¸Šæ±‡æŠ¥æ–‡æ¡ˆå’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ä¿®æ”¹ï¼Œè¯·è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹ã€‚"""
                
                with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                    response_container = st.empty()
                    full_response = ""
                    for chunk in call_gemini_stream(full_prompt, REPORT_ASSISTANT_SYSTEM_PROMPT):
                        if chunk["type"] == "text":
                            full_response += chunk["content"]
                            response_container.markdown(full_response + "â–Œ")
                        elif chunk["type"] == "error":
                            st.error(f"ç”Ÿæˆå¤±è´¥: {chunk['content']}")
                            break
                    
                    if full_response:
                        response_container.markdown(full_response)
                        add_chat_message(chat_key, "assistant", full_response)
                        st.rerun()
    
    # ========== å‘¨æŠ¥åŠ©æ‰‹åŠŸèƒ½ ==========
    elif function_mode == "å‘¨æŠ¥åŠ©æ‰‹":
        st.markdown("### ğŸ“… å‘¨æŠ¥åŠ©æ‰‹")
        st.markdown("å°†é›¶æ•£çš„æ—¥æŠ¥/å·¥ä½œè®°å½•æ±‡æ€»ã€æç‚¼ä¸ºé€»è¾‘æ¸…æ™°ã€é‡ç‚¹çªå‡ºçš„ä¸“ä¸šå‘¨æŠ¥ã€‚")
        
        # å¤§çš„å¤šè¡Œæ–‡æœ¬æ¡†
        daily_logs = st.text_area(
            "è¯·è¾“å…¥æœ¬å‘¨æ—¥æŠ¥/å·¥ä½œè®°å½•",
            height=400,
            placeholder="""è¯·è¾“å…¥æœ¬å‘¨çš„å·¥ä½œè®°å½•ï¼Œå¯ä»¥æ˜¯æ—¥æŠ¥æ±‡æ€»æˆ–å·¥ä½œæµæ°´...

ç¤ºä¾‹æ ¼å¼ï¼š
ã€å‘¨ä¸€ã€‘
- å®Œæˆæ¨èç®—æ³•çš„æ•°æ®åˆ†æï¼Œå‘ç°å¤´éƒ¨å›ºåŒ–é—®é¢˜
- ä¸äº§å“å¯¹é½ç‰¹è¾‘åˆ†ç±»æ¥æºé€»è¾‘

ã€å‘¨äºŒã€‘
- è°ƒæ•´æ··æ’ç­–ç•¥ï¼Œå¢åŠ "çƒ­é—¨è¶‹åŠ¿"å¤šæ ·æ€§
- ä¿®å¤ä½œå“æ›´æ–°åæœªé‡æ–°å®¡æ ¸çš„é—®é¢˜

ã€å‘¨ä¸‰ã€‘
- æ–°å¢å¹³å‡å¯¹å±€æ—¶é•¿å‡†å…¥ç­›é€‰æ¡ä»¶
- æé«˜äººå®¡ä¸¾æŠ¥é˜ˆå€¼ä»1è°ƒæ•´åˆ°5
...""",
            key="weekly_daily_logs"
        )
        
        # åˆå§‹åŒ–å‘¨æŠ¥åŠ©æ‰‹ç›¸å…³çš„session_state
        if "generated_weekly_report" not in st.session_state:
            st.session_state.generated_weekly_report = ""
        if "weekly_report_processing" not in st.session_state:
            st.session_state.weekly_report_processing = False
        
        # ç”ŸæˆæŒ‰é’®
        if st.button("ğŸ“ ç”Ÿæˆå‘¨æŠ¥", type="primary", disabled=st.session_state.weekly_report_processing):
            if not daily_logs.strip():
                st.error("è¯·è¾“å…¥æœ¬å‘¨æ—¥æŠ¥/å·¥ä½œè®°å½•ï¼")
            else:
                st.session_state.weekly_report_processing = True
                st.session_state.should_stop = False
                st.session_state.generated_weekly_report = ""
                st.session_state.saved_daily_logs = daily_logs
                st.session_state.weekly_saved_to_history = False  # é‡ç½®å†å²ä¿å­˜æ ‡è®°
                st.rerun()
        
        # å¤„ç†ç”Ÿæˆé˜¶æ®µ
        if st.session_state.weekly_report_processing:
            # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
            col_status, col_stop = st.columns([4, 1])
            with col_status:
                st.markdown("**âœï¸ æ­£åœ¨ç”Ÿæˆå‘¨æŠ¥...**")
            with col_stop:
                if st.button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", key="stop_weekly", type="secondary"):
                    st.session_state.should_stop = True
                    st.warning("æ­£åœ¨ä¸­æ­¢...")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            # è¾“å‡ºå®¹å™¨
            output_container = st.empty()
            
            # æ„å»ºPrompt
            saved_logs = st.session_state.get("saved_daily_logs", daily_logs)
            user_prompt = f"""
{WEEKLY_REPORT_SYSTEM_PROMPT}

Input Data (æœ¬å‘¨æ—¥æŠ¥/å·¥ä½œè®°å½•):
{saved_logs}
"""
            
            # è°ƒç”¨Gemini APIï¼ˆæµå¼ï¼‰
            full_response = ""
            thinking_content = ""
            was_stopped = False
            has_error = False
            error_message = ""
            
            for chunk in call_gemini_stream(user_prompt, ""):
                if st.session_state.should_stop:
                    was_stopped = True
                    break
                
                if chunk["type"] == "text":
                    full_response += chunk["content"]
                    output_container.markdown(full_response + "â–Œ")
                elif chunk["type"] == "thinking":
                    thinking_content += chunk["content"]
                    with thinking_expander:
                        thinking_container.markdown(thinking_content)
                elif chunk["type"] == "error":
                    has_error = True
                    error_message = chunk["content"]
                    break
                elif chunk["type"] == "retry":
                    st.info(chunk["content"])
            
            # ç§»é™¤å…‰æ ‡
            if full_response:
                output_container.markdown(full_response)
            
            # å¤„ç†ç»“æœ
            if has_error:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error_message}")
            elif was_stopped:
                st.warning("âš ï¸ ç”Ÿæˆå·²ä¸­æ­¢")
                if full_response:
                    st.session_state.generated_weekly_report = full_response
            else:
                st.success("âœ… å‘¨æŠ¥ç”Ÿæˆå®Œæˆï¼")
                st.session_state.generated_weekly_report = full_response
            
            st.session_state.weekly_report_processing = False
            st.session_state.should_stop = False
            st.rerun()
        
        # æ˜¾ç¤ºå·²ç”Ÿæˆçš„å‘¨æŠ¥ï¼ˆéå¤„ç†ä¸­çŠ¶æ€ï¼‰
        if st.session_state.generated_weekly_report and not st.session_state.weekly_report_processing:
            st.markdown("### ğŸ“„ ç”Ÿæˆçš„å‘¨æŠ¥")
            st.markdown(st.session_state.generated_weekly_report)
            
            # ä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ğŸ“‹ ä¸‹è½½å‘¨æŠ¥ (TXT)",
                data=st.session_state.generated_weekly_report,
                file_name="æœ¬å‘¨å‘¨æŠ¥.txt",
                mime="text/plain"
            )
            
            # ä¿å­˜åˆ°ä¼šè¯å†å²ï¼ˆä»…åœ¨é¦–æ¬¡å®Œæˆæ—¶ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
            if not st.session_state.get("weekly_saved_to_history"):
                add_to_history(
                    function_type="å‘¨æŠ¥åŠ©æ‰‹",
                    input_data={"å·¥ä½œè®°å½•": st.session_state.get("saved_daily_logs", "")[:200] + "..."},
                    output_data=st.session_state.generated_weekly_report,
                    download_data=st.session_state.generated_weekly_report.encode("utf-8"),
                    download_filename="æœ¬å‘¨å‘¨æŠ¥.txt",
                    download_mime="text/plain"
                )
                st.session_state.weekly_saved_to_history = True
            
            # ========== å¤šè½®å¯¹è¯åŒºåŸŸ ==========
            st.markdown("---")
            st.markdown("### ğŸ’¬ ç»§ç»­å¯¹è¯")
            st.caption("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®æˆ–è¦æ±‚ä¿®æ”¹ï¼ŒAIå°†åŸºäºå·²ç”Ÿæˆçš„å‘¨æŠ¥è¿›è¡Œå›ç­”ã€‚")
            
            # åˆå§‹åŒ–å¯¹è¯å†å²
            chat_key = "weekly_chat"
            init_chat_history(chat_key)
            
            # æ˜¾ç¤ºå¯¹è¯å†å²
            chat_history = get_chat_history(chat_key)
            if chat_history:
                for msg in chat_history:
                    if msg["role"] == "user":
                        st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                        st.info(msg["content"])
                    else:
                        st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                        st.markdown(msg["content"])
            
            # å¯¹è¯è¾“å…¥
            weekly_chat_col1, weekly_chat_col2, weekly_chat_col3 = st.columns([6, 1, 1])
            with weekly_chat_col1:
                weekly_chat_input = st.text_input(
                    "è¿½é—®æˆ–ä¿®æ”¹è¦æ±‚",
                    placeholder="ä¾‹å¦‚ï¼šè¯·è¡¥å……æ•°æ®åˆ†æéƒ¨åˆ†çš„å†…å®¹...",
                    key="weekly_chat_input",
                    label_visibility="collapsed"
                )
            with weekly_chat_col2:
                weekly_chat_send = st.button("å‘é€", key="weekly_chat_send", type="primary", use_container_width=True)
            with weekly_chat_col3:
                if st.button("æ¸…ç©º", key="weekly_chat_clear", use_container_width=True):
                    clear_chat_history(chat_key)
                    st.rerun()
            
            # å¤„ç†å¯¹è¯
            if weekly_chat_send and weekly_chat_input.strip():
                add_chat_message(chat_key, "user", weekly_chat_input)
                
                # æ„å»ºä¸Šä¸‹æ–‡
                function_context = f"""ã€å·²ç”Ÿæˆçš„å‘¨æŠ¥ã€‘
{st.session_state.generated_weekly_report}"""
                
                history_context = build_chat_context(chat_key, WEEKLY_REPORT_SYSTEM_PROMPT)
                full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{weekly_chat_input}

è¯·åŸºäºä»¥ä¸Šå‘¨æŠ¥å’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ä¿®æ”¹ï¼Œè¯·è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹ã€‚"""
                
                with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                    response_container = st.empty()
                    full_response = ""
                    for chunk in call_gemini_stream(full_prompt, WEEKLY_REPORT_SYSTEM_PROMPT):
                        if chunk["type"] == "text":
                            full_response += chunk["content"]
                            response_container.markdown(full_response + "â–Œ")
                        elif chunk["type"] == "error":
                            st.error(f"ç”Ÿæˆå¤±è´¥: {chunk['content']}")
                            break
                    
                    if full_response:
                        response_container.markdown(full_response)
                        add_chat_message(chat_key, "assistant", full_response)
                        st.rerun()
    
    # ========== ç™½çš®ä¹¦åŠ©æ‰‹åŠŸèƒ½ ==========
    elif function_mode == "ç™½çš®ä¹¦åŠ©æ‰‹":
        st.markdown("### ğŸ“– ç™½çš®ä¹¦åŠ©æ‰‹")
        st.markdown("å°†ç®€çŸ­çš„åŠŸèƒ½å…³é”®è¯æ‰©å†™ä¸ºæ ‡å‡†çš„PUBGM WoWæ¨¡å¼ç‰ˆæœ¬åŠŸèƒ½é™ˆè¿°ã€‚")
        
        # å•è¡Œæ–‡æœ¬æ¡†
        feature_keyword = st.text_input(
            "è¯·è¾“å…¥åŠŸèƒ½å…³é”®è¯",
            placeholder="ä¾‹å¦‚ï¼šåŠ¨ç”»ç”Ÿæˆã€è‡ªå®šä¹‰UIã€æ­¦è£…AIã€å…¨å±€å˜é‡...",
            key="whitepaper_keyword"
        )
        
        # åˆå§‹åŒ–ç™½çš®ä¹¦åŠ©æ‰‹ç›¸å…³çš„session_state
        if "generated_feature_desc" not in st.session_state:
            st.session_state.generated_feature_desc = ""
        if "whitepaper_processing" not in st.session_state:
            st.session_state.whitepaper_processing = False
        
        # ç”ŸæˆæŒ‰é’®
        if st.button("ğŸ“ ç”ŸæˆåŠŸèƒ½æè¿°", type="primary", disabled=st.session_state.whitepaper_processing):
            if not feature_keyword.strip():
                st.error("è¯·è¾“å…¥åŠŸèƒ½å…³é”®è¯ï¼")
            else:
                st.session_state.whitepaper_processing = True
                st.session_state.should_stop = False
                st.session_state.generated_feature_desc = ""
                st.session_state.saved_feature_keyword = feature_keyword
                st.session_state.whitepaper_saved_to_history = False  # é‡ç½®å†å²ä¿å­˜æ ‡è®°
                st.rerun()
        
        # å¤„ç†ç”Ÿæˆé˜¶æ®µ
        if st.session_state.whitepaper_processing:
            # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
            col_status, col_stop = st.columns([4, 1])
            with col_status:
                st.markdown("**âœï¸ æ­£åœ¨ç”ŸæˆåŠŸèƒ½æè¿°...**")
            with col_stop:
                if st.button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", key="stop_whitepaper", type="secondary"):
                    st.session_state.should_stop = True
                    st.warning("æ­£åœ¨ä¸­æ­¢...")
            
            # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
            thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
            with thinking_expander:
                thinking_container = st.empty()
            
            # è¾“å‡ºå®¹å™¨
            output_container = st.empty()
            
            # æ„å»ºPrompt
            saved_keyword = st.session_state.get("saved_feature_keyword", feature_keyword)
            user_prompt = f"""
{WHITEPAPER_ASSISTANT_SYSTEM_PROMPT}

---
è¯·è¾“å…¥åŠŸèƒ½å…³é”®è¯ï¼š
ã€{saved_keyword}ã€‘
"""
            
            # è°ƒç”¨Gemini APIï¼ˆæµå¼ï¼‰
            full_response = ""
            thinking_content = ""
            was_stopped = False
            has_error = False
            error_message = ""
            
            for chunk in call_gemini_stream(user_prompt, ""):
                if st.session_state.should_stop:
                    was_stopped = True
                    break
                
                if chunk["type"] == "text":
                    full_response += chunk["content"]
                    output_container.markdown(full_response + "â–Œ")
                elif chunk["type"] == "thinking":
                    thinking_content += chunk["content"]
                    with thinking_expander:
                        thinking_container.markdown(thinking_content)
                elif chunk["type"] == "error":
                    has_error = True
                    error_message = chunk["content"]
                    break
                elif chunk["type"] == "retry":
                    st.info(chunk["content"])
            
            # ç§»é™¤å…‰æ ‡
            if full_response:
                output_container.markdown(full_response)
            
            # å¤„ç†ç»“æœ
            if has_error:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error_message}")
            elif was_stopped:
                st.warning("âš ï¸ ç”Ÿæˆå·²ä¸­æ­¢")
                if full_response:
                    st.session_state.generated_feature_desc = full_response
            else:
                st.success("âœ… åŠŸèƒ½æè¿°ç”Ÿæˆå®Œæˆï¼")
                st.session_state.generated_feature_desc = full_response
            
            st.session_state.whitepaper_processing = False
            st.session_state.should_stop = False
            st.rerun()
        
        # æ˜¾ç¤ºå·²ç”Ÿæˆçš„åŠŸèƒ½æè¿°ï¼ˆéå¤„ç†ä¸­çŠ¶æ€ï¼‰
        if st.session_state.generated_feature_desc and not st.session_state.whitepaper_processing:
            st.markdown("### ğŸ“„ ç”Ÿæˆçš„åŠŸèƒ½æè¿°")
            st.markdown(st.session_state.generated_feature_desc)
            
            # ä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ğŸ“‹ ä¸‹è½½åŠŸèƒ½æè¿° (TXT)",
                data=st.session_state.generated_feature_desc,
                file_name="åŠŸèƒ½æè¿°.txt",
                mime="text/plain"
            )
            
            # ä¿å­˜åˆ°ä¼šè¯å†å²ï¼ˆä»…åœ¨é¦–æ¬¡å®Œæˆæ—¶ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
            if not st.session_state.get("whitepaper_saved_to_history"):
                add_to_history(
                    function_type="ç™½çš®ä¹¦åŠ©æ‰‹",
                    input_data={"åŠŸèƒ½å…³é”®è¯": st.session_state.get("saved_feature_keyword", "")},
                    output_data=st.session_state.generated_feature_desc,
                    download_data=st.session_state.generated_feature_desc.encode("utf-8"),
                    download_filename="åŠŸèƒ½æè¿°.txt",
                    download_mime="text/plain"
                )
                st.session_state.whitepaper_saved_to_history = True
            
            # ========== å¤šè½®å¯¹è¯åŒºåŸŸ ==========
            st.markdown("---")
            st.markdown("### ğŸ’¬ ç»§ç»­å¯¹è¯")
            st.caption("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®æˆ–è¦æ±‚ä¿®æ”¹ï¼ŒAIå°†åŸºäºå·²ç”Ÿæˆçš„åŠŸèƒ½æè¿°è¿›è¡Œå›ç­”ã€‚")
            
            # åˆå§‹åŒ–å¯¹è¯å†å²
            chat_key = "whitepaper_chat"
            init_chat_history(chat_key)
            
            # æ˜¾ç¤ºå¯¹è¯å†å²
            chat_history = get_chat_history(chat_key)
            if chat_history:
                for msg in chat_history:
                    if msg["role"] == "user":
                        st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                        st.info(msg["content"])
                    else:
                        st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                        st.markdown(msg["content"])
            
            # å¯¹è¯è¾“å…¥
            wp_chat_col1, wp_chat_col2, wp_chat_col3 = st.columns([6, 1, 1])
            with wp_chat_col1:
                wp_chat_input = st.text_input(
                    "è¿½é—®æˆ–ä¿®æ”¹è¦æ±‚",
                    placeholder="ä¾‹å¦‚ï¼šè¯·å†ç”Ÿæˆä¸€ä¸ªå…³äºæ­¦è£…AIçš„åŠŸèƒ½æè¿°...",
                    key="whitepaper_chat_input",
                    label_visibility="collapsed"
                )
            with wp_chat_col2:
                wp_chat_send = st.button("å‘é€", key="whitepaper_chat_send", type="primary", use_container_width=True)
            with wp_chat_col3:
                if st.button("æ¸…ç©º", key="whitepaper_chat_clear", use_container_width=True):
                    clear_chat_history(chat_key)
                    st.rerun()
            
            # å¤„ç†å¯¹è¯
            if wp_chat_send and wp_chat_input.strip():
                add_chat_message(chat_key, "user", wp_chat_input)
                
                # æ„å»ºä¸Šä¸‹æ–‡
                function_context = f"""ã€å·²ç”Ÿæˆçš„åŠŸèƒ½æè¿°ã€‘
{st.session_state.generated_feature_desc}"""
                
                history_context = build_chat_context(chat_key, WHITEPAPER_ASSISTANT_SYSTEM_PROMPT)
                full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{wp_chat_input}

è¯·åŸºäºä»¥ä¸Šå†…å®¹å’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ç”Ÿæˆæ–°çš„åŠŸèƒ½æè¿°ï¼Œè¯·æŒ‰ç…§æ ‡å‡†å¥å¼è¾“å‡ºã€‚"""
                
                with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                    response_container = st.empty()
                    full_response = ""
                    for chunk in call_gemini_stream(full_prompt, WHITEPAPER_ASSISTANT_SYSTEM_PROMPT):
                        if chunk["type"] == "text":
                            full_response += chunk["content"]
                            response_container.markdown(full_response + "â–Œ")
                        elif chunk["type"] == "error":
                            st.error(f"ç”Ÿæˆå¤±è´¥: {chunk['content']}")
                            break
                    
                    if full_response:
                        response_container.markdown(full_response)
                        add_chat_message(chat_key, "assistant", full_response)
                        st.rerun()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: gray;'>"
        "ğŸ® æ¸¸æˆç­–åˆ’Agentï¼ˆé…¸å¥¶ï¼‰ | Powered by Gemini API"
        "</div>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
