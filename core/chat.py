"""
å¤šè½®å¯¹è¯ç®¡ç†æ¨¡å—
ç®¡ç†å„åŠŸèƒ½æ¨¡å—çš„å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡
"""

import streamlit as st
from datetime import datetime
from typing import Optional

from .api import call_gemini_stream


def init_chat_history(chat_key: str):
    """
    åˆå§‹åŒ–æŒ‡å®šåŠŸèƒ½çš„å¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®åï¼ˆå¦‚ 'generate_chat', 'report_chat' ç­‰ï¼‰
    """
    if chat_key not in st.session_state:
        st.session_state[chat_key] = []


def add_chat_message(chat_key: str, role: str, content: str):
    """
    æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        role: è§’è‰²ï¼ˆ'user' æˆ– 'assistant'ï¼‰
        content: æ¶ˆæ¯å†…å®¹
    """
    init_chat_history(chat_key)
    st.session_state[chat_key].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().strftime("%H:%M:%S")
    })


def get_chat_history(chat_key: str) -> list:
    """
    è·å–å¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
    
    Returns:
        å¯¹è¯å†å²åˆ—è¡¨
    """
    init_chat_history(chat_key)
    return st.session_state[chat_key]


def clear_chat_history(chat_key: str):
    """
    æ¸…ç©ºå¯¹è¯å†å²
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
    """
    st.session_state[chat_key] = []


def build_chat_context(chat_key: str, system_prompt: str, max_history: int = 10) -> str:
    """
    æ„å»ºåŒ…å«å¯¹è¯å†å²çš„ä¸Šä¸‹æ–‡Prompt
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        max_history: æœ€å¤§å†å²æ¶ˆæ¯æ•°é‡
    
    Returns:
        åŒ…å«å†å²ä¸Šä¸‹æ–‡çš„å®Œæ•´Prompt
    """
    history = get_chat_history(chat_key)
    
    if not history:
        return ""
    
    # åªå–æœ€è¿‘çš„Næ¡å†å²
    recent_history = history[-max_history:] if len(history) > max_history else history
    
    # æ„å»ºå¯¹è¯å†å²æ–‡æœ¬
    history_text = "\n\nã€å¯¹è¯å†å²ã€‘\n"
    for msg in recent_history:
        role_label = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
        history_text += f"{role_label}: {msg['content']}\n\n"
    
    return history_text


def render_chat_interface(chat_key: str, system_prompt: str, container, 
                          placeholder: str = "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–ä¿®æ”¹è¦æ±‚...",
                          function_context: str = ""):
    """
    æ¸²æŸ“å¤šè½®å¯¹è¯ç•Œé¢
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        container: Streamlitå®¹å™¨
        placeholder: è¾“å…¥æ¡†å ä½æ–‡æœ¬
        function_context: å½“å‰åŠŸèƒ½çš„ä¸Šä¸‹æ–‡ï¼ˆå¦‚å·²ç”Ÿæˆçš„å†…å®¹ï¼‰
    
    Returns:
        æ˜¯å¦æœ‰æ–°çš„å¯¹è¯äº§ç”Ÿ
    """
    init_chat_history(chat_key)
    history = get_chat_history(chat_key)
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    if history:
        with container:
            st.markdown("#### ğŸ’¬ å¯¹è¯å†å²")
            for i, msg in enumerate(history):
                if msg["role"] == "user":
                    st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                    st.info(msg["content"])
                else:
                    st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                    st.markdown(msg["content"])
            st.markdown("---")
    
    # ç”¨äºæ§åˆ¶å¯¹è¯è¾“å…¥çš„çŠ¶æ€
    chat_input_key = f"{chat_key}_input"
    chat_processing_key = f"{chat_key}_processing"
    
    if chat_processing_key not in st.session_state:
        st.session_state[chat_processing_key] = False
    
    # å¯¹è¯è¾“å…¥åŒºåŸŸ
    col_input, col_btn, col_clear = container.columns([6, 1, 1])
    
    with col_input:
        user_message = st.text_input(
            "ç»§ç»­å¯¹è¯",
            placeholder=placeholder,
            key=chat_input_key,
            label_visibility="collapsed"
        )
    
    with col_btn:
        send_clicked = st.button("å‘é€", key=f"{chat_key}_send", type="primary", use_container_width=True)
    
    with col_clear:
        if st.button("æ¸…ç©º", key=f"{chat_key}_clear", use_container_width=True):
            clear_chat_history(chat_key)
            st.rerun()
    
    return send_clicked, user_message, chat_processing_key


def process_chat_message(chat_key: str, user_message: str, system_prompt: str, 
                         function_context: str, output_container):
    """
    å¤„ç†ç”¨æˆ·çš„å¯¹è¯æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤
    
    Args:
        chat_key: å¯¹è¯å†å²çš„é”®å
        user_message: ç”¨æˆ·æ¶ˆæ¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        function_context: å½“å‰åŠŸèƒ½çš„ä¸Šä¸‹æ–‡
        output_container: è¾“å‡ºå®¹å™¨
    
    Returns:
        ç”Ÿæˆçš„å›å¤å†…å®¹
    """
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    add_chat_message(chat_key, "user", user_message)
    
    # æ„å»ºå®Œæ•´çš„Prompt
    history_context = build_chat_context(chat_key, system_prompt)
    
    full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{user_message}

è¯·åŸºäºä»¥ä¸Šä¸Šä¸‹æ–‡å’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚"""
    
    # è°ƒç”¨APIç”Ÿæˆå›å¤
    full_response = ""
    was_stopped = False
    has_error = False
    error_message = ""
    
    for chunk in call_gemini_stream(full_prompt, system_prompt):
        if st.session_state.should_stop:
            was_stopped = True
            break
        
        if chunk["type"] == "text":
            full_response += chunk["content"]
            output_container.markdown(full_response + "â–Œ")
        elif chunk["type"] == "error":
            has_error = True
            error_message = chunk["content"]
            break
        elif chunk["type"] == "retry":
            st.info(chunk["content"])
    
    # ç§»é™¤å…‰æ ‡
    if full_response:
        output_container.markdown(full_response)
    
    # å¤„ç†ç»“æœ
    if has_error:
        return None, error_message
    elif was_stopped:
        if full_response:
            add_chat_message(chat_key, "assistant", full_response)
        return full_response, "å·²ä¸­æ­¢"
    else:
        add_chat_message(chat_key, "assistant", full_response)
        return full_response, None
