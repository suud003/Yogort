"""
ç™½çš®ä¹¦åŠ©æ‰‹åŠŸèƒ½æ¨¡å—
å°†åŠŸèƒ½å…³é”®è¯æ‰©å†™ä¸ºæ ‡å‡†çš„ç‰ˆæœ¬åŠŸèƒ½é™ˆè¿°
"""

import streamlit as st

from ..core.api import call_gemini_stream
from ..core.chat import (
    init_chat_history, add_chat_message, get_chat_history,
    clear_chat_history, build_chat_context
)
from ..core.history import add_to_history
from ..config.prompts import WHITEPAPER_ASSISTANT_SYSTEM_PROMPT


def render_whitepaper_assistant():
    """æ¸²æŸ“ç™½çš®ä¹¦åŠ©æ‰‹åŠŸèƒ½ç•Œé¢"""
    st.markdown("### ğŸ“– ç™½çš®ä¹¦åŠ©æ‰‹")
    st.markdown("å°†ç®€çŸ­çš„åŠŸèƒ½å…³é”®è¯æ‰©å†™ä¸ºæ ‡å‡†çš„PUBGM WoWæ¨¡å¼ç‰ˆæœ¬åŠŸèƒ½é™ˆè¿°ã€‚")
    
    # å•è¡Œæ–‡æœ¬æ¡†
    feature_keyword = st.text_input(
        "è¯·è¾“å…¥åŠŸèƒ½å…³é”®è¯",
        placeholder="ä¾‹å¦‚ï¼šåŠ¨ç”»ç”Ÿæˆã€è‡ªå®šä¹‰UIã€æ­¦è£…AIã€å…¨å±€å˜é‡...",
        key="whitepaper_keyword"
    )
    
    # åˆå§‹åŒ–ç™½çš®ä¹¦åŠ©æ‰‹ç›¸å…³çš„session_state
    if "generated_feature_desc" not in st.session_state:
        st.session_state.generated_feature_desc = ""
    if "whitepaper_processing" not in st.session_state:
        st.session_state.whitepaper_processing = False
    
    # ç”ŸæˆæŒ‰é’®
    if st.button("ğŸ“ ç”ŸæˆåŠŸèƒ½æè¿°", type="primary", disabled=st.session_state.whitepaper_processing):
        if not feature_keyword.strip():
            st.error("è¯·è¾“å…¥åŠŸèƒ½å…³é”®è¯ï¼")
        else:
            st.session_state.whitepaper_processing = True
            st.session_state.should_stop = False
            st.session_state.generated_feature_desc = ""
            st.session_state.saved_feature_keyword = feature_keyword
            st.session_state.whitepaper_saved_to_history = False
            st.rerun()
    
    # å¤„ç†ç”Ÿæˆé˜¶æ®µ
    if st.session_state.whitepaper_processing:
        _process_whitepaper_generation(feature_keyword)
    
    # æ˜¾ç¤ºå·²ç”Ÿæˆçš„åŠŸèƒ½æè¿°ï¼ˆéå¤„ç†ä¸­çŠ¶æ€ï¼‰
    if st.session_state.generated_feature_desc and not st.session_state.whitepaper_processing:
        _display_whitepaper_result()


def _process_whitepaper_generation(feature_keyword: str):
    """å¤„ç†åŠŸèƒ½æè¿°ç”Ÿæˆè¿‡ç¨‹"""
    # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
    col_status, col_stop = st.columns([4, 1])
    with col_status:
        st.markdown("**âœï¸ æ­£åœ¨ç”ŸæˆåŠŸèƒ½æè¿°...**")
    with col_stop:
        if st.button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", key="stop_whitepaper", type="secondary"):
            st.session_state.should_stop = True
            st.warning("æ­£åœ¨ä¸­æ­¢...")
    
    # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
    thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
    with thinking_expander:
        thinking_container = st.empty()
    
    # è¾“å‡ºå®¹å™¨
    output_container = st.empty()
    
    # æ„å»ºPrompt
    saved_keyword = st.session_state.get("saved_feature_keyword", feature_keyword)
    user_prompt = f"""
{WHITEPAPER_ASSISTANT_SYSTEM_PROMPT}

---
è¯·è¾“å…¥åŠŸèƒ½å…³é”®è¯ï¼š
ã€{saved_keyword}ã€‘
"""
    
    # è°ƒç”¨Gemini APIï¼ˆæµå¼ï¼‰
    full_response = ""
    thinking_content = ""
    was_stopped = False
    has_error = False
    error_message = ""
    
    for chunk in call_gemini_stream(user_prompt, ""):
        if st.session_state.should_stop:
            was_stopped = True
            break
        
        if chunk["type"] == "text":
            full_response += chunk["content"]
            output_container.markdown(full_response + "â–Œ")
        elif chunk["type"] == "thinking":
            thinking_content += chunk["content"]
            with thinking_expander:
                thinking_container.markdown(thinking_content)
        elif chunk["type"] == "error":
            has_error = True
            error_message = chunk["content"]
            break
        elif chunk["type"] == "retry":
            st.info(chunk["content"])
    
    # ç§»é™¤å…‰æ ‡
    if full_response:
        output_container.markdown(full_response)
    
    # å¤„ç†ç»“æœ
    if has_error:
        st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error_message}")
    elif was_stopped:
        st.warning("âš ï¸ ç”Ÿæˆå·²ä¸­æ­¢")
        if full_response:
            st.session_state.generated_feature_desc = full_response
    else:
        st.success("âœ… åŠŸèƒ½æè¿°ç”Ÿæˆå®Œæˆï¼")
        st.session_state.generated_feature_desc = full_response
    
    st.session_state.whitepaper_processing = False
    st.session_state.should_stop = False
    st.rerun()


def _display_whitepaper_result():
    """æ˜¾ç¤ºåŠŸèƒ½æè¿°ç»“æœå’Œå¤šè½®å¯¹è¯ç•Œé¢"""
    st.markdown("### ğŸ“„ ç”Ÿæˆçš„åŠŸèƒ½æè¿°")
    st.markdown(st.session_state.generated_feature_desc)
    
    # ä¸‹è½½æŒ‰é’®
    st.download_button(
        label="ğŸ“‹ ä¸‹è½½åŠŸèƒ½æè¿° (TXT)",
        data=st.session_state.generated_feature_desc,
        file_name="åŠŸèƒ½æè¿°.txt",
        mime="text/plain"
    )
    
    # ä¿å­˜åˆ°ä¼šè¯å†å²ï¼ˆä»…åœ¨é¦–æ¬¡å®Œæˆæ—¶ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
    if not st.session_state.get("whitepaper_saved_to_history"):
        add_to_history(
            function_type="ç™½çš®ä¹¦åŠ©æ‰‹",
            input_data={"åŠŸèƒ½å…³é”®è¯": st.session_state.get("saved_feature_keyword", "")},
            output_data=st.session_state.generated_feature_desc,
            download_data=st.session_state.generated_feature_desc.encode("utf-8"),
            download_filename="åŠŸèƒ½æè¿°.txt",
            download_mime="text/plain"
        )
        st.session_state.whitepaper_saved_to_history = True
    
    # ========== å¤šè½®å¯¹è¯åŒºåŸŸ ==========
    st.markdown("---")
    st.markdown("### ğŸ’¬ ç»§ç»­å¯¹è¯")
    st.caption("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®æˆ–è¦æ±‚ä¿®æ”¹ï¼ŒAIå°†åŸºäºå·²ç”Ÿæˆçš„åŠŸèƒ½æè¿°è¿›è¡Œå›ç­”ã€‚")
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    chat_key = "whitepaper_chat"
    init_chat_history(chat_key)
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    chat_history = get_chat_history(chat_key)
    if chat_history:
        for msg in chat_history:
            if msg["role"] == "user":
                st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                st.info(msg["content"])
            else:
                st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                st.markdown(msg["content"])
    
    # å¯¹è¯è¾“å…¥
    wp_chat_col1, wp_chat_col2, wp_chat_col3 = st.columns([6, 1, 1])
    with wp_chat_col1:
        wp_chat_input = st.text_input(
            "è¿½é—®æˆ–ä¿®æ”¹è¦æ±‚",
            placeholder="ä¾‹å¦‚ï¼šè¯·å†ç”Ÿæˆä¸€ä¸ªå…³äºæ­¦è£…AIçš„åŠŸèƒ½æè¿°...",
            key="whitepaper_chat_input",
            label_visibility="collapsed"
        )
    with wp_chat_col2:
        wp_chat_send = st.button("å‘é€", key="whitepaper_chat_send", type="primary", use_container_width=True)
    with wp_chat_col3:
        if st.button("æ¸…ç©º", key="whitepaper_chat_clear", use_container_width=True):
            clear_chat_history(chat_key)
            st.rerun()
    
    # å¤„ç†å¯¹è¯
    if wp_chat_send and wp_chat_input.strip():
        add_chat_message(chat_key, "user", wp_chat_input)
        
        # æ„å»ºä¸Šä¸‹æ–‡
        function_context = f"""ã€å·²ç”Ÿæˆçš„åŠŸèƒ½æè¿°ã€‘
{st.session_state.generated_feature_desc}"""
        
        history_context = build_chat_context(chat_key, WHITEPAPER_ASSISTANT_SYSTEM_PROMPT)
        full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{wp_chat_input}

è¯·åŸºäºä»¥ä¸Šå†…å®¹å’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ç”Ÿæˆæ–°çš„åŠŸèƒ½æè¿°ï¼Œè¯·æŒ‰ç…§æ ‡å‡†å¥å¼è¾“å‡ºã€‚"""
        
        with st.spinner("æ­£åœ¨æ€è€ƒ..."):
            response_container = st.empty()
            full_response = ""
            for chunk in call_gemini_stream(full_prompt, WHITEPAPER_ASSISTANT_SYSTEM_PROMPT):
                if chunk["type"] == "text":
                    full_response += chunk["content"]
                    response_container.markdown(full_response + "â–Œ")
                elif chunk["type"] == "error":
                    st.error(f"ç”Ÿæˆå¤±è´¥: {chunk['content']}")
                    break
            
            if full_response:
                response_container.markdown(full_response)
                add_chat_message(chat_key, "assistant", full_response)
                st.rerun()
