"""
å‘¨æŠ¥åŠ©æ‰‹åŠŸèƒ½æ¨¡å—
å°†é›¶æ•£çš„æ—¥æŠ¥/å·¥ä½œè®°å½•æ±‡æ€»ä¸ºä¸“ä¸šå‘¨æŠ¥
"""

import streamlit as st

from ..core.api import call_gemini_stream
from ..core.chat import (
    init_chat_history, add_chat_message, get_chat_history,
    clear_chat_history, build_chat_context
)
from ..core.history import add_to_history
from ..config.prompts import WEEKLY_REPORT_SYSTEM_PROMPT


def render_weekly_report():
    """æ¸²æŸ“å‘¨æŠ¥åŠ©æ‰‹åŠŸèƒ½ç•Œé¢"""
    st.markdown("### ğŸ“… å‘¨æŠ¥åŠ©æ‰‹")
    st.markdown("å°†é›¶æ•£çš„æ—¥æŠ¥/å·¥ä½œè®°å½•æ±‡æ€»ã€æç‚¼ä¸ºé€»è¾‘æ¸…æ™°ã€é‡ç‚¹çªå‡ºçš„ä¸“ä¸šå‘¨æŠ¥ã€‚")
    
    # å¤§çš„å¤šè¡Œæ–‡æœ¬æ¡†
    daily_logs = st.text_area(
        "è¯·è¾“å…¥æœ¬å‘¨æ—¥æŠ¥/å·¥ä½œè®°å½•",
        height=400,
        placeholder="""è¯·è¾“å…¥æœ¬å‘¨çš„å·¥ä½œè®°å½•ï¼Œå¯ä»¥æ˜¯æ—¥æŠ¥æ±‡æ€»æˆ–å·¥ä½œæµæ°´...

ç¤ºä¾‹æ ¼å¼ï¼š
ã€å‘¨ä¸€ã€‘
- å®Œæˆæ¨èç®—æ³•çš„æ•°æ®åˆ†æï¼Œå‘ç°å¤´éƒ¨å›ºåŒ–é—®é¢˜
- ä¸äº§å“å¯¹é½ç‰¹è¾‘åˆ†ç±»æ¥æºé€»è¾‘

ã€å‘¨äºŒã€‘
- è°ƒæ•´æ··æ’ç­–ç•¥ï¼Œå¢åŠ "çƒ­é—¨è¶‹åŠ¿"å¤šæ ·æ€§
- ä¿®å¤ä½œå“æ›´æ–°åæœªé‡æ–°å®¡æ ¸çš„é—®é¢˜

ã€å‘¨ä¸‰ã€‘
- æ–°å¢å¹³å‡å¯¹å±€æ—¶é•¿å‡†å…¥ç­›é€‰æ¡ä»¶
- æé«˜äººå®¡ä¸¾æŠ¥é˜ˆå€¼ä»1è°ƒæ•´åˆ°5
...""",
        key="weekly_daily_logs"
    )
    
    # åˆå§‹åŒ–å‘¨æŠ¥åŠ©æ‰‹ç›¸å…³çš„session_state
    if "generated_weekly_report" not in st.session_state:
        st.session_state.generated_weekly_report = ""
    if "weekly_report_processing" not in st.session_state:
        st.session_state.weekly_report_processing = False
    
    # ç”ŸæˆæŒ‰é’®
    if st.button("ğŸ“ ç”Ÿæˆå‘¨æŠ¥", type="primary", disabled=st.session_state.weekly_report_processing):
        if not daily_logs.strip():
            st.error("è¯·è¾“å…¥æœ¬å‘¨æ—¥æŠ¥/å·¥ä½œè®°å½•ï¼")
        else:
            st.session_state.weekly_report_processing = True
            st.session_state.should_stop = False
            st.session_state.generated_weekly_report = ""
            st.session_state.saved_daily_logs = daily_logs
            st.session_state.weekly_saved_to_history = False
            st.rerun()
    
    # å¤„ç†ç”Ÿæˆé˜¶æ®µ
    if st.session_state.weekly_report_processing:
        _process_weekly_report_generation(daily_logs)
    
    # æ˜¾ç¤ºå·²ç”Ÿæˆçš„å‘¨æŠ¥ï¼ˆéå¤„ç†ä¸­çŠ¶æ€ï¼‰
    if st.session_state.generated_weekly_report and not st.session_state.weekly_report_processing:
        _display_weekly_report_result()


def _process_weekly_report_generation(daily_logs: str):
    """å¤„ç†å‘¨æŠ¥ç”Ÿæˆè¿‡ç¨‹"""
    # æ˜¾ç¤ºä¸­æ­¢æŒ‰é’®å’ŒçŠ¶æ€
    col_status, col_stop = st.columns([4, 1])
    with col_status:
        st.markdown("**âœï¸ æ­£åœ¨ç”Ÿæˆå‘¨æŠ¥...**")
    with col_stop:
        if st.button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", key="stop_weekly", type="secondary"):
            st.session_state.should_stop = True
            st.warning("æ­£åœ¨ä¸­æ­¢...")
    
    # æ€è€ƒè¿‡ç¨‹å±•ç¤ºåŒºåŸŸ
    thinking_expander = st.expander("ğŸ’­ æŸ¥çœ‹æ¨¡å‹æ€è€ƒè¿‡ç¨‹", expanded=False)
    with thinking_expander:
        thinking_container = st.empty()
    
    # è¾“å‡ºå®¹å™¨
    output_container = st.empty()
    
    # æ„å»ºPrompt
    saved_logs = st.session_state.get("saved_daily_logs", daily_logs)
    user_prompt = f"""
{WEEKLY_REPORT_SYSTEM_PROMPT}

Input Data (æœ¬å‘¨æ—¥æŠ¥/å·¥ä½œè®°å½•):
{saved_logs}
"""
    
    # è°ƒç”¨Gemini APIï¼ˆæµå¼ï¼‰
    full_response = ""
    thinking_content = ""
    was_stopped = False
    has_error = False
    error_message = ""
    
    for chunk in call_gemini_stream(user_prompt, ""):
        if st.session_state.should_stop:
            was_stopped = True
            break
        
        if chunk["type"] == "text":
            full_response += chunk["content"]
            output_container.markdown(full_response + "â–Œ")
        elif chunk["type"] == "thinking":
            thinking_content += chunk["content"]
            with thinking_expander:
                thinking_container.markdown(thinking_content)
        elif chunk["type"] == "error":
            has_error = True
            error_message = chunk["content"]
            break
        elif chunk["type"] == "retry":
            st.info(chunk["content"])
    
    # ç§»é™¤å…‰æ ‡
    if full_response:
        output_container.markdown(full_response)
    
    # å¤„ç†ç»“æœ
    if has_error:
        st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error_message}")
    elif was_stopped:
        st.warning("âš ï¸ ç”Ÿæˆå·²ä¸­æ­¢")
        if full_response:
            st.session_state.generated_weekly_report = full_response
    else:
        st.success("âœ… å‘¨æŠ¥ç”Ÿæˆå®Œæˆï¼")
        st.session_state.generated_weekly_report = full_response
    
    st.session_state.weekly_report_processing = False
    st.session_state.should_stop = False
    st.rerun()


def _display_weekly_report_result():
    """æ˜¾ç¤ºå‘¨æŠ¥ç»“æœå’Œå¤šè½®å¯¹è¯ç•Œé¢"""
    st.markdown("### ğŸ“„ ç”Ÿæˆçš„å‘¨æŠ¥")
    st.markdown(st.session_state.generated_weekly_report)
    
    # ä¸‹è½½æŒ‰é’®
    st.download_button(
        label="ğŸ“‹ ä¸‹è½½å‘¨æŠ¥ (TXT)",
        data=st.session_state.generated_weekly_report,
        file_name="æœ¬å‘¨å‘¨æŠ¥.txt",
        mime="text/plain"
    )
    
    # ä¿å­˜åˆ°ä¼šè¯å†å²ï¼ˆä»…åœ¨é¦–æ¬¡å®Œæˆæ—¶ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
    if not st.session_state.get("weekly_saved_to_history"):
        add_to_history(
            function_type="å‘¨æŠ¥åŠ©æ‰‹",
            input_data={"å·¥ä½œè®°å½•": st.session_state.get("saved_daily_logs", "")[:200] + "..."},
            output_data=st.session_state.generated_weekly_report,
            download_data=st.session_state.generated_weekly_report.encode("utf-8"),
            download_filename="æœ¬å‘¨å‘¨æŠ¥.txt",
            download_mime="text/plain"
        )
        st.session_state.weekly_saved_to_history = True
    
    # ========== å¤šè½®å¯¹è¯åŒºåŸŸ ==========
    st.markdown("---")
    st.markdown("### ğŸ’¬ ç»§ç»­å¯¹è¯")
    st.caption("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®æˆ–è¦æ±‚ä¿®æ”¹ï¼ŒAIå°†åŸºäºå·²ç”Ÿæˆçš„å‘¨æŠ¥è¿›è¡Œå›ç­”ã€‚")
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    chat_key = "weekly_chat"
    init_chat_history(chat_key)
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    chat_history = get_chat_history(chat_key)
    if chat_history:
        for msg in chat_history:
            if msg["role"] == "user":
                st.markdown(f"**ğŸ§‘ ç”¨æˆ·** _{msg['timestamp']}_")
                st.info(msg["content"])
            else:
                st.markdown(f"**ğŸ¤– åŠ©æ‰‹** _{msg['timestamp']}_")
                st.markdown(msg["content"])
    
    # å¯¹è¯è¾“å…¥
    weekly_chat_col1, weekly_chat_col2, weekly_chat_col3 = st.columns([6, 1, 1])
    with weekly_chat_col1:
        weekly_chat_input = st.text_input(
            "è¿½é—®æˆ–ä¿®æ”¹è¦æ±‚",
            placeholder="ä¾‹å¦‚ï¼šè¯·è¡¥å……æ•°æ®åˆ†æéƒ¨åˆ†çš„å†…å®¹...",
            key="weekly_chat_input",
            label_visibility="collapsed"
        )
    with weekly_chat_col2:
        weekly_chat_send = st.button("å‘é€", key="weekly_chat_send", type="primary", use_container_width=True)
    with weekly_chat_col3:
        if st.button("æ¸…ç©º", key="weekly_chat_clear", use_container_width=True):
            clear_chat_history(chat_key)
            st.rerun()
    
    # å¤„ç†å¯¹è¯
    if weekly_chat_send and weekly_chat_input.strip():
        add_chat_message(chat_key, "user", weekly_chat_input)
        
        # æ„å»ºä¸Šä¸‹æ–‡
        function_context = f"""ã€å·²ç”Ÿæˆçš„å‘¨æŠ¥ã€‘
{st.session_state.generated_weekly_report}"""
        
        history_context = build_chat_context(chat_key, WEEKLY_REPORT_SYSTEM_PROMPT)
        full_prompt = f"""{function_context}

{history_context}

ã€å½“å‰ç”¨æˆ·è¾“å…¥ã€‘
{weekly_chat_input}

è¯·åŸºäºä»¥ä¸Šå‘¨æŠ¥å’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ä¿®æ”¹ï¼Œè¯·è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹ã€‚"""
        
        with st.spinner("æ­£åœ¨æ€è€ƒ..."):
            response_container = st.empty()
            full_response = ""
            for chunk in call_gemini_stream(full_prompt, WEEKLY_REPORT_SYSTEM_PROMPT):
                if chunk["type"] == "text":
                    full_response += chunk["content"]
                    response_container.markdown(full_response + "â–Œ")
                elif chunk["type"] == "error":
                    st.error(f"ç”Ÿæˆå¤±è´¥: {chunk['content']}")
                    break
            
            if full_response:
                response_container.markdown(full_response)
                add_chat_message(chat_key, "assistant", full_response)
                st.rerun()
